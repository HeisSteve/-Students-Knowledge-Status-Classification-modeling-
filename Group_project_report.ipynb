{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31c9838-e838-4f27-9e43-c0e096e59bad",
   "metadata": {},
   "source": [
    "Title (Steve, Eva, Liam, Jacky)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8567e-3e9d-443b-a290-38fb1fcca3dc",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "provide some relevant background information on the topic so that someone unfamiliar with it will be prepared to understand the rest of your report\n",
    "clearly state the question you tried to answer with your project\n",
    "identify and describe the dataset that was used to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ef0ef-02ef-4f8d-8a01-8221cd8ecb6b",
   "metadata": {},
   "source": [
    "Data Set information: \n",
    "The dataset was collected by Kaâ€‹â€‹hraman et al. The weighting system and development of quantitative measurements for the variables was done using Kahramans rule based system which gives quantitative values(ratings) to students' performances in certain academic related parameters. The parameters:\n",
    "\n",
    "\n",
    "STG: Refers to Study time rating(0-1), the amount time spend studying about Electrical DC Machines.\n",
    "\n",
    "SCG: Refers to Repetition rating(0-1),  the amount of problems, material the student worked on. For example, worksheets, tutorials.\n",
    "\n",
    "PEG: Refers to the exam performance rating of the subject(0-1), in this case, the exam performance on Electrical DC Machine course.\n",
    "\n",
    "STR: Refers to Study time rating of related subjects(0-1), the amount of time students spent studying related topics.\n",
    "\n",
    "LPR; Refers to exam performance rating in related subjects(0-1), exam performance on related material, or background information.\n",
    "\n",
    "*UNS(): Refers to student understanding levels; Based on the weighting system Kahramans uses in his rule based system paper, classified  as â€œVery-lowâ€ â€œLowâ€, â€œMiddleâ€, or â€œHighâ€ Understanding of Electrical DC Machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b881f-fc4f-4e39-b139-40ab544bc888",
   "metadata": {},
   "source": [
    "Methods & Results:\n",
    "\n",
    "describe in written English the methods you used to perform your analysis from beginning to end that narrates the code the does the analysis.\n",
    "your report should include code which:\n",
    "loads data from the original source on the web \n",
    "wrangles and cleans the data from it's original (downloaded) format to the format necessary for the planned analysis\n",
    "performs a summary of the data set that is relevant for exploratory data analysis related to the planned analysis \n",
    "creates a visualization of the dataset that is relevant for exploratory data analysis related to the planned analysis\n",
    "performs the data analysis\n",
    "creates a visualization of the analysis \n",
    "note: all tables and figure should have a figure/table number and a legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be55856-429e-4856-b135-dd04ff8a5978",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. loading in all the packages for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac48163a-2af9-45e9-9945-b235dfef88fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "â”€â”€ \u001b[1mAttaching packages\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2 â”€â”€\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.2     \u001b[32mâœ”\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mtibble \u001b[39m 3.2.1     \u001b[32mâœ”\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32mâœ”\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3     \n",
      "â”€â”€ \u001b[1mConflicts\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "â”€â”€ \u001b[1mAttaching packages\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.0.0 â”€â”€\n",
      "\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.2     \u001b[32mâœ”\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mdials       \u001b[39m 1.1.0     \u001b[32mâœ”\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32mâœ”\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.2\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.1     \u001b[32mâœ”\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.3     \u001b[32mâœ”\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.4     \n",
      "\n",
      "â”€â”€ \u001b[1mConflicts\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34mâ€¢\u001b[39m Use suppressPackageStartupMessages() to eliminate package startup messages\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(cowplot): there is no package called â€˜cowplotâ€™\n",
     "output_type": "error",
     "traceback": [
      "Error in library(cowplot): there is no package called â€˜cowplotâ€™\nTraceback:\n",
      "1. library(cowplot)"
     ]
    }
   ],
   "source": [
    "install.packages(\"themis\")\n",
    "install.packages(\"kknn\")\n",
    "library(kknn)\n",
    "library(purrr)\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(themis)\n",
    "library(cowplot)\n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0672b-228d-4bd9-8bc4-009d154dd4c8",
   "metadata": {},
   "source": [
    "### 2. Reading in the data from the web, and Preparation of Data analysis\n",
    "\n",
    "#### (A) loading the data\n",
    "After loading the data, we factorize the variable we want to predict, UNS, by using the function as.factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a99637-f678-45af-b949-c2269430277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) \n",
    "options(repr.plot.height = 5, repr.plot.width = 6)\n",
    "\n",
    "##Loading data\n",
    "url <- \"https://github.com/JackyLinllk/ubc_dsci100_assignment/raw/main/data/Data_User_Modeling_Dataset_full.csv\"\n",
    "knowledge_data<-read_csv(url)|>\n",
    "    select(STG:UNS)|>\n",
    "    mutate(UNS = as.factor(UNS))\n",
    "knowledge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afff09a-4242-47bd-b4ff-eef72ef8f863",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Table 1: Dataset Of Students' Knowledge Status\n",
    "    This table represents the students' knowledge status about the subject of Electrical DC Machines. \n",
    "    For specific meaning of the columns refer back to the intro about the \"Data set Information\".\n",
    "\n",
    "    The dataset had been obtained from: \n",
    "     Kahraman,Hamdi, Colak,Ilhami, and Sagiroglu,Seref. (2013). \n",
    "    User Knowledge Modeling. UCI Machine Learning Repository. https://doi.org/10.24432/C5231X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d0424-fbf1-4b51-a37b-ef2f29cd0813",
   "metadata": {},
   "source": [
    "#### (B) NA-values\n",
    "We then check for NA-values, and realized that the last row restores NA-values across all the variables, so we just simply deleted the last row of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd867a2-b42e-4045-9112-070b725a928e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Check NA rows\n",
    "na_row= which(!complete.cases(knowledge_data))\n",
    "print(na_row)\n",
    "\n",
    "##Delete the NA row of the data\n",
    "knowledge_data= knowledge_data[-nrow(knowledge_data),]\n",
    "knowledge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13853f31-e585-4fa9-a3a9-76dfab1dfda8",
   "metadata": {},
   "source": [
    "##### Table 2: Dataset Of Students' Knowledge Status with removed NA-Values\n",
    " Data set after the NA-Values are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286f353-d420-471b-a7e5-34cd4da0273c",
   "metadata": {},
   "source": [
    "#### C) Final prep \n",
    "We check the dataâ€™s tidiness from \"Table 2\" by looking into 3 factors, which are: (1) each row is a single observation, (2) Each column is a single variable, (3) Each value is in single cell. \n",
    "\n",
    "\n",
    "After checking the data is tidy, we utilize function called\n",
    "group_by with summarize to find the summary statistics of the number of observations in\n",
    "each factor level with the corresponding proportion (Table 3).\n",
    "\n",
    "We realize that under the quantitative variable named UNS, the factor levels\n",
    "named â€œvery_lowâ€ and â€œVery Lowâ€ should be in the same level. Thus, we apply the function\n",
    "mutate with function fct_recode to merge two factor levels into one\n",
    "\n",
    "On top of that, we realized the\n",
    "classifier is class imbalance, which means the proportion for each stratum is not equally\n",
    "proportional. Thus, we apply the functions called uc_recipe and step_upsample to rebalance\n",
    "the rare class, namely â€œVery Lowâ€, by oversampling. Then, we again utilize group_by with\n",
    "summarize to check each stratum is equally proportional to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1bfdc-a5bb-4d7e-9422-498ab55e312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Summary table and checking for Proportion \n",
    "class_prop = knowledge_data|>\n",
    "  group_by(UNS)|>\n",
    "  summarize(count = n(),\n",
    "            percentage= count/nrow(knowledge_data))\n",
    "class_prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea3358-9dcc-4b70-9289-68d7d052a083",
   "metadata": {},
   "source": [
    "##### Table 3: Summary Statistics of The number of Observations Knowledge Levels\n",
    "    This table represents the summary statistics of the number of observations in\n",
    "    each factor level with the corresponding proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0d8d7-40f4-4262-bb13-101a6b304a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Typo in the dataset #very_low and Very Low should be same observation\n",
    "knowledge_data= knowledge_data|>\n",
    "  mutate(UNS = fct_recode(UNS, \"Very Low\" =  \"very_low\"))\n",
    "\n",
    "##Balancing the data\n",
    "ups_recipe= recipe(UNS~. ,data=knowledge_data)|>\n",
    "  step_upsample(UNS, over_ratio=1, skip=F)|>\n",
    "  prep()\n",
    "upsampled_knowledge=bake(ups_recipe, knowledge_data)\n",
    "\n",
    "##Checking the balance\n",
    "upsampled_knowledge|>\n",
    "  group_by(UNS)|>\n",
    "  summarize(n=n())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4a109-ad79-4098-9c9b-a5ad345324b9",
   "metadata": {},
   "source": [
    "##### Table 5: Summary Statistics of The number of Observations Knowledge Levels After Balancing the Data\n",
    "    This table represents the summary statistics with upsampleding to Balance the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b2acd-63ea-4e94-81a5-6d98f134c5a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Spliting the data into 70% properation of training data and testing data\n",
    "\n",
    "We separated the data using the initial_split function to create 2 subsets, namely training set and testing set.\n",
    "Inside the initial_split function, we set strata argument to the categorical variable UNS. The\n",
    "training and testing functions are used to create two different data frames with the\n",
    "corresponding weight of 70% and 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7dc004-98a0-4db8-98f6-2c2673373f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split the data into training set and testing set\n",
    "knowledge_data_split <- initial_split(upsampled_knowledge, prop = 0.70, strata = UNS)  \n",
    "knowledge_data_split_train <- training(knowledge_data_split)\n",
    "knowledge_data_split_test <- testing(knowledge_data_split)\n",
    "\n",
    "knowledge_data_split_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca7ba6-6a1d-426f-ac99-f454d3d44d44",
   "metadata": {},
   "source": [
    "##### Table 6: The Training set of Student's Knowledge \n",
    "    This table represents the training set we're utilizing to train our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3868ebd-cde0-4ef9-857e-ebe061d20a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_data_split_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4d3ad-d35d-4cd3-b342-737973d3ca45",
   "metadata": {},
   "source": [
    "##### Table 7: The Testing set of Student's Knowledge \n",
    "    This table represents the testing set we're utilizing to evaluate our models with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54033257-b10c-4291-8a73-bb797e232c74",
   "metadata": {
    "tags": []
   },
   "source": [
    " #### 4. Parameter selection: Finding the best K value\n",
    " Our next step is to find the best K value which maximizes the accuracy for our model,\n",
    "where K is the number of neighbors. We will be using cross-validation with validation set of\n",
    "5 in the training set to find the best possible k value. In other words, we will split our\n",
    "training data into 5 training sets. \n",
    "\n",
    "Firstly, we apply nearest_neighbor, set_engine, and set_mode\n",
    "functions to create a model specification. Inside the nearest_neighbor function, the argument\n",
    "weight_func is set to rectangular, which means each k neighbor are equally important. For\n",
    "the neighbors argument, tune() is telling the framework to find the different parameter values\n",
    "for K.\n",
    "\n",
    "Since KNN classification uses Euclidean distance between points, so it is very sensitive\n",
    "to the different types of scale. Thus, we planned to standardize the variables for all chosen\n",
    "variables to ensure the predictive algorithms are accurate and unbiased. We managed to\n",
    "standardize all the variables by using the recipe function with step_center(all_predictors()) and\n",
    "step_scale(all_predictors()).\n",
    "\n",
    "For cross-validation, we use vfold_cv function to set the validation set into 5 folds\n",
    "by using the training set. Finally, we create a tribble with neighbors and use the seq function to\n",
    "set the K-values to odd numbers (e.g., 1,3,5... ğ‘›). The reason why we donâ€™t want even\n",
    "numbers is because each neighbor is equally weighted; therefore, the even numbers will\n",
    "cause confusion.\n",
    "\n",
    "Finally, we put everything into workflow to chain all the steps together to get the\n",
    "accuracy of different K-values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d52f4e-485b-4118-9a6a-13cdc930ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Finding the k value for best accuracy\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "##Choosing all the variables as predictors, and standardize it\n",
    "data_recipe <- recipe(UNS ~. , data = knowledge_data_split_train)|>\n",
    "  step_center(all_predictors())|>\n",
    "  step_scale(all_predictors())\n",
    "\n",
    "training_vfold <-  vfold_cv(knowledge_data_split_train, v=5, strata = UNS)\n",
    "\n",
    "k_value = 101\n",
    "K <- tibble(neighbors = seq(1,k_value,2))\n",
    "\n",
    "knn_result <- workflow() |>\n",
    "  add_recipe(data_recipe) |>\n",
    "  add_model(knn_tune)|>\n",
    "  tune_grid(resamples = training_vfold, grid = K) |>\n",
    "  collect_metrics()|>\n",
    "  filter(.metric == \"accuracy\")\n",
    "knn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d548a-8315-408d-8a1f-75c1439d695f",
   "metadata": {},
   "source": [
    "##### Table 8: Accuracy of different K values  \n",
    "    This table represents the Accuracy of different K values from 1 to 101, Advancing by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1c516-514b-4406-99fc-4bab9ed02b0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Visualizing the optimal K-value\n",
    "\n",
    "We used the ggplot function to create a line graph which\n",
    "helps to visualize the accuracy trends under corresponding K-values. Surprisingly, when the\n",
    "K=1, we have the most accurate K-value for the model. Thus, we choose K equals to one as\n",
    "our optimal K-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78578a7d-c4bf-46c4-850d-f18041014dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scatter plot on the accuracy and number of neighbors\n",
    "cross_val_plot <- ggplot(knn_result, aes(x=neighbors, y= mean)) +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "  ggtitle(label= \"KNN Accuracy verses Number of Neighbors\")\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197522e1-5d9f-490f-b945-2c63a24a2b0b",
   "metadata": {},
   "source": [
    "##### Plot 1: KNN Accuracy verses Number of Neighbors\n",
    "    This plot represents the Virtualization of \"Table 7\". Notably, the Highest accuracy came from a K neighbor of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfae034-fcf7-4e67-a0ab-a0ecbf32860f",
   "metadata": {},
   "source": [
    "#### 6. Creating the model with the optimal K-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9bc19-5097-49e5-9b06-5fedaebe4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding confusion matrix of model using testing set\n",
    "knn_best_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 1) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "\n",
    "knn_fit <- workflow() |>\n",
    "  add_recipe(data_recipe) |>\n",
    "  add_model(knn_best_tune)|>\n",
    "  fit(knowledge_data_split_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698f2fe-19dd-4207-986f-8376a14f61d0",
   "metadata": {},
   "source": [
    "#### 7. Predicting the model on the testing data set, and evaluating the model\n",
    "\n",
    "After we have our confusion matrix, we are planning to calculate the corresponding\n",
    "accuracy, precision, and recall for all the diagonal entries (where ğ‘– = ğ‘—). Since the confusion\n",
    "matrix is in the list, we first convert it into matrix form.\n",
    "For the accuracy calculation, we apply the formula: ğ´ğ‘ğ‘ğ‘¢ğ‘Ÿğ‘ğ‘ğ‘¦ = ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›\n",
    "ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  ,\n",
    "where the number of correct predictions are the diagonal entries, and the total number of\n",
    "predictions are the sum of all entries. In R, we can simply calculate the accuracy by:\n",
    "sum(diag(matrix))/sum(matrix)\n",
    "For precision calculation, the formula is: ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› = ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ \n",
    "ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  ,\n",
    "where the number of correct positive predictions corresponds to the specific diagonal value,\n",
    "and the total number of positive predictions are the sum of rows in that diagonal value.\n",
    "Thus, we will be calculating all the diagonal entries one by one. For example,\n",
    "ğ¶ğ‘š,ğ‘š = ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥[ğ‘š,ğ‘š]/(ğ‘ ğ‘¢ğ‘š(ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥[ğ‘š,]))\n",
    "Then we take the average of all diagonal entries to find the average precision for our model.\n",
    "For recall calculation, the formula is: ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ = ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ \n",
    "ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ ğ‘¡ğ‘’ğ‘ ğ‘¡ ğ‘ ğ‘’ğ‘¡ ğ‘œğ‘ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ , where\n",
    "the number of correct positive predictions are the specific diagonal value, and the total\n",
    "number of positive test set observations are the sum of the column in that diagonal value.\n",
    "For example,\n",
    "ğ¶ğ‘š,ğ‘š = ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥[ğ‘š,ğ‘š]/(ğ‘ ğ‘¢ğ‘š(ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥[,ğ‘š]))\n",
    "Similarly, we will take the average of all diagonal entries to find the average recall for our\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016d3a9-8b2e-4f57-9c8c-b11f4a227daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Predicting the UNS of testing data set\n",
    "knowledge_predictions= knn_fit|>\n",
    "  predict(knowledge_data_split_test)|>\n",
    "  bind_cols(knowledge_data_split_test)\n",
    "knowledge_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591dceb-1e34-4cf6-aaff-1a1e5d14f07b",
   "metadata": {},
   "source": [
    "##### Table 9: Predicted knowledge levels\n",
    "    This table represents the predicted knowledge level using the model, with the original testing set(Table 7). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f979d-398c-4b94-b63f-bf17eca1a5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_metrics= knowledge_predictions|>\n",
    "  metrics(truth= UNS, estimate = .pred_class)|>\n",
    "  filter(.metric== \"accuracy\")\n",
    "knowledge_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50466c8-1f1b-4ffd-945b-e5c0f16f2d78",
   "metadata": {},
   "source": [
    "##### Table 10: Accuracy of our model\n",
    "    This table represents the Accuracy of our model, ie ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘› / ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™ ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ ğ‘œğ‘“ ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ \n",
    "    Looking at the value of the .estimate variable, it shows that our model has an estimated accuracy on the testing set of ~92.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad585f-f765-43f1-9b4f-ad469a80c823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_conf_mat= knowledge_predictions|>\n",
    "  conf_mat(truth= UNS, estimate = .pred_class)\n",
    "knowledge_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb761f2-95ab-439c-858c-c66cd361ebae",
   "metadata": {},
   "source": [
    "##### Table 11: Confusion matrix \n",
    "    This table represents the true number of each Knowledge level, and the Predicted number of each Knowledge level.\n",
    "    Looking at the table, The highest number of missed predictions of the Knowledge level came from the \"low\" class, \n",
    "    with a total of 8 missed predictions. All the other Knowledge level had only one missed predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc1265-582b-46dc-b41e-7134646737e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating the Accuracy/Precision/Recall\n",
    "knowledge_matrix= matrix(unlist(knowledge_conf_mat), nrow = 4) ##Convert list into 5x5 matrix\n",
    "\n",
    "knowledge_accuracy= sum(diag(knowledge_matrix))/sum(knowledge_matrix) #Accuracy\n",
    "\n",
    "knowledge_precision_high= knowledge_matrix[1,1]/(sum(knowledge_matrix[,1]))#precision for high\n",
    "knowledge_precision_low= knowledge_matrix[2,2]/(sum(knowledge_matrix[,2]))#precision for low\n",
    "knowledge_precision_middle= knowledge_matrix[3,3]/(sum(knowledge_matrix[,3]))#precision for middle\n",
    "knowledge_precision_very_low= knowledge_matrix[4,4]/(sum(knowledge_matrix[,4]))#precision for very low\n",
    "average_precision= mean(knowledge_precision_high,\n",
    "                        knowledge_precision_low, \n",
    "                        knowledge_precision_middle,\n",
    "                        nowledge_precision_very_low)\n",
    "\n",
    "\n",
    "knowledge_recall_high= knowledge_matrix[1,1]/(sum(knowledge_matrix[1,]))#Recall for high\n",
    "knowledge_recall_low= knowledge_matrix[2,2]/(sum(knowledge_matrix[2,]))#Recall for low\n",
    "knowledge_recall_middle= knowledge_matrix[3,3]/(sum(knowledge_matrix[3,]))#Recall for middle\n",
    "knowledge_recall_very_low= knowledge_matrix[4,4]/(sum(knowledge_matrix[4,]))#Recall for very low\n",
    "average_recall= mean(knowledge_recall_high,\n",
    "                        knowledge_recall_low, \n",
    "                        knowledge_recall_middle,\n",
    "                        nowledge_recall_very_low)\n",
    "\n",
    "\n",
    "summary_prediction= data.frame(\n",
    "   accuracy= knowledge_accuracy,\n",
    "   precision= average_precision, \n",
    "   average_recall)\n",
    "\n",
    "summary_prediction\n",
    "\n",
    "knowledge_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36bc03-4432-4916-911b-d54f819c73d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Number of Predicted cases \n",
    "count <- knowledge_predictions|>\n",
    "    group_by(.pred_class) |>\n",
    "    summarize(count = n())|>\n",
    "    rename(UNS = .pred_class)|>\n",
    "    mutate(UNS = fct_recode(UNS, pred_High = \"High\", pred_Low = \"Low\", pred_Middle = \"Middle\", pred_Very_low = \"Very Low\"))\n",
    "\n",
    "#Number of True cases \n",
    "count2 <- knowledge_predictions|>\n",
    "    group_by(UNS) |>\n",
    "    summarize(count = n())\n",
    "\n",
    "## Combining the Number of Predicted cases with Number of True cases \n",
    "count3 <- rbind(count, count2)|>\n",
    "    mutate(pred_or_true = UNS)|>\n",
    "     mutate(pred_or_true = fct_recode(UNS, Pred = \"pred_High\", Pred = \"pred_Low\", Pred = \"pred_Middle\", Pred = \"pred_Very_low\",\n",
    "                                     True = \"High\",\n",
    "                                     True = \"Low\",\n",
    "                                     True = \"Middle\",\n",
    "                                     True = \"Very Low\"))\n",
    "count3\n",
    "\n",
    "Compare_High <- count3|>\n",
    "    filter(UNS == \"pred_High\" | UNS== \"High\") |>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted High vs True High\")\n",
    "\n",
    "Compare_Middle <- count3|>\n",
    "    filter(UNS == \"pred_Middle\" | UNS== \"Middle\") |>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted Middle vs True Middle\")\n",
    "\n",
    "\n",
    "Compare_Low <- count3|>\n",
    "    filter(UNS== \"pred_Low\" , UNS== \"Low\")|>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted Low vs True Low\")\n",
    "\n",
    "Compare_Very_Low <- count3|>\n",
    "    filter(UNS== \"pred_Very_low\" , UNS== \"Very Low\")|>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted Very Low vs True Very Low\")\n",
    "\n",
    "plot_grid(Compare_High, Compare_Middle,Compare_Low, Compare_Very_Low, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6b578-f508-44b1-a1ce-f4e45be8339a",
   "metadata": {},
   "source": [
    "##### Plot 2: Predicted vs True\n",
    "    This plot represents the Virtualization of \"Table 11\". Notably..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b9986-51d6-43c1-9407-9077a10c6c44",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "summarize what you found\n",
    "discuss whether this is what you expected to find?\n",
    "discuss what impact could such findings have?\n",
    "discuss what future questions could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754dd40-aabb-4cf3-8ce2-3baed199553c",
   "metadata": {},
   "source": [
    "References\n",
    "At least 2 citations of literature relevant to the project (format is your choice, just be consistent across the references).\n",
    "Make sure to cite the source of your data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25121a35-11bc-4d0c-9f57-7df5f7a43803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

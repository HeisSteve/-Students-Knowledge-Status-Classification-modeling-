{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83de434b",
   "metadata": {},
   "source": [
    "### **Students' Knowledge Status**\n",
    "\n",
    "**Group: Liam Brennan, Eva He, Li-Kun Lin, Steve He** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ce6a1",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "The objective of any class should be to increase student’s understanding of the topic subject. Students with a high understanding of class material will enter the workforce with the tools they need to succeed in their relevant subjects. We will classify students' understanding of class materials based on five quantitative variables taken from Kahraman et al’s User Knowledge Modeling dataset.\n",
    "The question our project will try to answer is : Can we predict student's knowledge level based on 5 different academic parameters using the Knn-classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d6aeb",
   "metadata": {},
   "source": [
    "Data Set information: \n",
    "The dataset was collected by Ka​​hraman et al. The weighting system and development of quantitative measurements for the variables was done using Kahramans rule based system which gives quantitative values(ratings) to students' performances in certain academic related parameters. The parameters:\n",
    "\n",
    "\n",
    "STG: Refers to Study time rating(0-1), the amount time spend studying about Electrical DC Machines.\n",
    "\n",
    "SCG: Refers to Repetition rating(0-1),  the amount of problems, material the student worked on. For example, worksheets, tutorials.\n",
    "\n",
    "PEG: Refers to the exam performance rating of the subject(0-1), in this case, the exam performance on Electrical DC Machine course.\n",
    "\n",
    "STR: Refers to Study time rating of related subjects(0-1), the amount of time students spent studying related topics.\n",
    "\n",
    "LPR; Refers to exam performance rating in related subjects(0-1), exam performance on related material, or background information.\n",
    "\n",
    "*UNS(): Refers to student understanding levels; Based on the weighting system Kahramans uses in his rule based system paper, classified  as “Very-low” “Low”, “Middle”, or “High” Understanding of Electrical DC Machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82cdf1",
   "metadata": {},
   "source": [
    "Methods & Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76959f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. loading in all the packages for data analysis\n",
    "This analysis utilizes the knn classification algorithm to predict the knowledge level (High, Middle, Low or Very Low) of students. First, all the packages that are necessary to perform this algorithm are loaded into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install.packages(\"themis\")\n",
    "install.packages(\"kknn\")\n",
    "install.packages(\"cowplot\")\n",
    "library(kknn)\n",
    "library(purrr)\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(themis)\n",
    "library(cowplot)\n",
    "options(repr.matrix.max.rows = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca9cfb",
   "metadata": {},
   "source": [
    "### 2. Reading in the data from the web, and Preparation of Data analysis\n",
    "\n",
    "#### (A) loading the data\n",
    "After loading the data, we factorize the variable we want to predict, UNS, by using the function as.factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc717e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234) \n",
    "options(repr.plot.height = 5, repr.plot.width = 6)\n",
    "\n",
    "##Loading data\n",
    "url <- \"https://github.com/JackyLinllk/ubc_dsci100_assignment/raw/main/data/Data_User_Modeling_Dataset_full.csv\"\n",
    "knowledge_data<-read_csv(url)|>\n",
    "    select(STG:UNS)|>\n",
    "    mutate(UNS = as.factor(UNS))\n",
    "knowledge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b4c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Table 1: Dataset Of Students' Knowledge Status\n",
    "    This table represents the students' knowledge status about the subject of Electrical DC Machines. \n",
    "    For specific meaning of the columns refer back to the intro about the \"Data set Information\".\n",
    "\n",
    "    The dataset had been obtained from: \n",
    "     Kahraman,Hamdi, Colak,Ilhami, and Sagiroglu,Seref. (2013). \n",
    "    User Knowledge Modeling. UCI Machine Learning Repository. https://doi.org/10.24432/C5231X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8792cf9",
   "metadata": {},
   "source": [
    "#### (B) NA-values\n",
    "We then check for NA-values, and realized that the last row restores NA-values across all the variables, so we just simply deleted the last row of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77947080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Check NA rows\n",
    "na_row= which(!complete.cases(knowledge_data))\n",
    "print(na_row)\n",
    "\n",
    "##Delete the NA row of the data\n",
    "knowledge_data= knowledge_data[-nrow(knowledge_data),]\n",
    "knowledge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db3f15",
   "metadata": {},
   "source": [
    "##### Table 2: Dataset Of Students' Knowledge Status with removed NA-Values\n",
    " Data set after the NA-Values are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99121cc",
   "metadata": {},
   "source": [
    "#### C) Prelimary Anlaysis and Final prep \n",
    "We check the data’s tidiness from \"Table 2\" by looking into 3 factors, which are: (1) each row is a single observation, (2) Each column is a single variable, (3) Each value is in single cell. \n",
    "\n",
    "\n",
    "After checking the data is tidy, we utilize function called\n",
    "group_by with summarize to find the summary statistics of the number of observations in\n",
    "each factor level with the corresponding proportion (Table 3).\n",
    "\n",
    "We realize that under the quantitative variable named UNS, the factor levels\n",
    "named “very_low” and “Very Low” should be in the same level. Thus, we apply the function\n",
    "mutate with function `fct_recode` to merge two factor levels into one\n",
    "\n",
    "On top of that, we realized the\n",
    "classifier is class imbalance, which means the proportion for each stratum is not equally\n",
    "proportional. Thus, we apply the functions called `uc_recipe` and `step_upsample` to rebalance\n",
    "the rare class, namely “Very Low”, by oversampling. Then, we again utilize group_by with\n",
    "summarize to check each stratum is equally proportional to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Summary table and checking for Proportion \n",
    "class_prop = knowledge_data|>\n",
    "  group_by(UNS)|>\n",
    "  summarize(count = n(),\n",
    "            percentage= count/nrow(knowledge_data))\n",
    "class_prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b327c7d",
   "metadata": {},
   "source": [
    "##### Table 3: Summary Statistics of The number of Observations Knowledge Levels\n",
    "    This table represents the summary statistics of the number of observations in\n",
    "    each factor level with the corresponding proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f072d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Typo in the dataset #very_low and Very Low should be same observation\n",
    "knowledge_data= knowledge_data|>\n",
    "  mutate(UNS = fct_recode(UNS, \"Very Low\" =  \"very_low\"))\n",
    "\n",
    "##Balancing the data\n",
    "ups_recipe= recipe(UNS~. ,data=knowledge_data)|>\n",
    "  step_upsample(UNS, over_ratio=1, skip=F)|>\n",
    "  prep()\n",
    "upsampled_knowledge=bake(ups_recipe, knowledge_data)\n",
    "\n",
    "##Checking the balance\n",
    "upsampled_knowledge|>\n",
    "  group_by(UNS)|>\n",
    "  summarize(n=n())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747c1dc",
   "metadata": {},
   "source": [
    "##### Table 5: Summary Statistics of The number of Observations Knowledge Levels After Balancing the Data\n",
    "    This table represents the summary statistics with upsampleding to Balance the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac172a78",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Spliting the data into 70% properation of training data and testing data\n",
    "\n",
    "#### A) Spliting the data \n",
    "We separated the data using the `initial_split` function to create 2 subsets, namely training set and testing set.\n",
    "Inside the initial_split function, we set strata argument to the categorical variable UNS. The\n",
    "training and testing functions are used to create two different data frames with the\n",
    "corresponding weight of 70% and 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split the data into training set and testing set\n",
    "knowledge_data_split <- initial_split(upsampled_knowledge, prop = 0.70, strata = UNS)  \n",
    "knowledge_data_split_train <- training(knowledge_data_split)\n",
    "knowledge_data_split_test <- testing(knowledge_data_split)\n",
    "\n",
    "knowledge_data_split_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703cc323",
   "metadata": {},
   "source": [
    "##### Table 6: The Training set of Student's Knowledge \n",
    "    This table represents the training set we're utilizing to train our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26235ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_data_split_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ca706",
   "metadata": {},
   "source": [
    "##### Table 7: The Testing set of Student's Knowledge \n",
    "    This table represents the testing set we're utilizing to evaluate our models with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b5911",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### B) Prelimary Anlaysis on the Training set \n",
    "we did the Prelimary Anlaysis by creating a table(using `group_by` and `summarize`) that looks at the count of each Knowledge level(Table 7), and \n",
    "creating a plot that compares all the variables, changing the y variables.\n",
    "\n",
    "The summary table(Table 7) shows that our attempt of balancing the data did work.\n",
    "Plot 1, shows that the variables we plotted can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe311ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_training_summary <- knowledge_data_split_train|>\n",
    "    group_by(UNS)|>\n",
    "    summarize(count = n())\n",
    "data_training_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3184a",
   "metadata": {},
   "source": [
    "##### Table 7: Summary Statistics of The number of Observations Knowledge Levels of Training data\n",
    "    This table represents the summary statistics of the number of obseravtion in each knowledge level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46779709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 16, repr.plot.height = 10)\n",
    "data_pairs <- knowledge_data_split_train |> \n",
    "     select(STG:PEG)|>\n",
    "     ggpairs(aes(alpha = 0.05)) +\n",
    "     theme(text = element_text(size = 20))\n",
    "data_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a40c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height = 18, repr.plot.width = 8)\n",
    "data_plot_LPR_PEG <- ggplot(knowledge_data_split_train, aes(x= LPR,y= PEG, color = UNS))+\n",
    "    geom_point() +\n",
    "    labs(x=\"Exam performance Rating \\n in Related Subject (0-1)\", y= \"Exam performance Rating \\n in Subject (0-1)\", color = \"Knowledge level\")+\n",
    "    ggtitle(\"Exam Performance vs Exam performance in Related Subject\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "\n",
    "data_plot_STG_PEG <- ggplot(knowledge_data_split_train, aes(x= STG,y= PEG, color = UNS))+\n",
    "    geom_point() +\n",
    "    labs(x=\"Study time rating (0-1)\", y= \"Exam performance Rating \\n in Subject (0-1)\", color = \"Knowledge level\")+\n",
    "    ggtitle(\"Exam Performance vs Study time rating\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "\n",
    "data_plot_SCG_PEG <- ggplot(knowledge_data_split_train, aes(x= SCG,y= PEG, color = UNS))+\n",
    "    geom_point() +\n",
    "    labs(x=\"Repetition rating (0-1)\", y= \"Exam performance Rating \\n in Subject (0-1)\", color = \"Knowledge level\")+\n",
    "    ggtitle(\"Exam Performance vs Repetition rating \")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "\n",
    "data_plot_STR_PEG <- ggplot(knowledge_data_split_train, aes(x= STR,y= PEG, color = UNS))+\n",
    "    geom_point() +\n",
    "    labs(x=\"Study time rating \\n in Related Subject (0-1)\", y= \"Exam performance Rating \\n in Subject (0-1)\", color = \"Knowledge level\")+\n",
    "    ggtitle(\"Exam Performance vs Study time rating in Related Subject\")+\n",
    "    theme(text = element_text(size = 15))\n",
    "\n",
    "\n",
    "\n",
    "plot_grid(data_plot_LPR_PEG, data_plot_STG_PEG, data_plot_SCG_PEG, data_plot_STR_PEG, ncol = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcdeab",
   "metadata": {},
   "source": [
    "##### Plot 1: The Relationship Between the Variables  \n",
    "    This plot represents the Virtualization of Relationship. It is clear from these plot that the all the different Variables can indeed be distinguish between the different knowledge levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd16eff",
   "metadata": {
    "tags": []
   },
   "source": [
    " #### 4. Parameter selection: Finding the best K value\n",
    "Our next step is to find the best K value and selecting the predictor variables  which maximizes the accuracy for our model.\n",
    "\n",
    "Firstly, we apply nearest_neighbor, set_engine, and set_mode\n",
    "functions to create a model specification. Inside the `nearest_neighbor function`, the argument\n",
    "`weight_func` is set to rectangular, which means each k neighbor are equally important. For\n",
    "the neighbors argument, `tune()` is telling the framework to find the different parameter values\n",
    "for K.\n",
    "\n",
    "For selecting the K  variable, where K is the number of neighbors. We will be using cross-validation with validation set of 5 in the training set to find the best possible k value. In other words, we will split our\n",
    "training data into 5 training sets. \n",
    "\n",
    "For cross-validation, we use `vfold_cv` function to set the validation set into 5 folds\n",
    "by using the training set. Finally, we create a tribble with neighbors and use the seq function to\n",
    "set the K-values to odd numbers (e.g., 1,3,5... 𝑛). The reason why we don’t want even\n",
    "numbers is because each neighbor is equally weighted; therefore, the even numbers will\n",
    "cause confusion.\n",
    "\n",
    "For selecting the predictor variables for recipe, we based it off of the research article where this dataset came from. The article mentioned that in predicting the user knowledge levels, the most useful variable to consider are the Study time rating(STG), the Repetition rating( SCG), the exam performance rating(PEG) of the subject, the Study time rating(STR) of related subjects, and the exam performance rating in related subjects(LPR). Basically all the variables (ref). And from Plot 1, we can also see that indeed distinctions between the different knowledge levels can be made with all the different variables. \n",
    "\n",
    "Since KNN classification uses Euclidean distance between points, so it is very sensitive\n",
    "to the different types of scale. Thus, we planned to standardize the variables for all chosen\n",
    "variables to ensure the predictive algorithms are accurate and unbiased. We managed to\n",
    "standardize all the variables by using the recipe function with `step_center(all_predictors())` and\n",
    "`step_scale(all_predictors())`.\n",
    "\n",
    "Finally, we put everything into workflow to chain all the steps together to get the\n",
    "accuracy of different K-values. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f065e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Finding the k value for best accuracy\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "##Choosing all the variables as predictors, and standardize it\n",
    "data_recipe <- recipe(UNS ~. , data = knowledge_data_split_train)|>\n",
    "  step_center(all_predictors())|>\n",
    "  step_scale(all_predictors())\n",
    "\n",
    "training_vfold <-  vfold_cv(knowledge_data_split_train, v=5, strata = UNS)\n",
    "\n",
    "k_value = 101\n",
    "K <- tibble(neighbors = seq(1,k_value,2))\n",
    "\n",
    "knn_result <- workflow() |>\n",
    "  add_recipe(data_recipe) |>\n",
    "  add_model(knn_tune)|>\n",
    "  tune_grid(resamples = training_vfold, grid = K) |>\n",
    "  collect_metrics()|>\n",
    "  filter(.metric == \"accuracy\")\n",
    "knn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ee413",
   "metadata": {},
   "source": [
    "##### Table 8: Accuracy of different K values  \n",
    "    This table represents the Accuracy of different K values from 1 to 101, Advancing by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299a1bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Visualizing the optimal K-value\n",
    "\n",
    "We used the ggplot function to create a line graph which\n",
    "helps to visualize the accuracy trends under corresponding K-values. Surprisingly, when the\n",
    "K=1, we have the most accurate K-value for the model. Thus, we choose K equals to one as\n",
    "our optimal K-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scatter plot on the accuracy and number of neighbors\n",
    "options(repr.plot.height = 8, repr.plot.width = 8)\n",
    "cross_val_plot <- ggplot(knn_result, aes(x=neighbors, y= mean)) +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "  ggtitle(label= \"KNN Accuracy verses Number of Neighbors\")\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0ecc0",
   "metadata": {},
   "source": [
    "##### Plot 2: KNN Accuracy verses Number of Neighbors\n",
    "    This plot represents the Virtualization of \"Table 7\". Notably, the Highest accuracy came from a K neighbor of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a4127",
   "metadata": {},
   "source": [
    "#### 6. Creating the model with the optimal K-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79488043",
   "metadata": {
    "tags": []
   },
   "source": [
    "We Chose the K value based on Plot 2, where the highest accuracy is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b00fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding confusion matrix of model using testing set\n",
    "knn_best_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 1) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "\n",
    "knn_fit <- workflow() |>\n",
    "  add_recipe(data_recipe) |>\n",
    "  add_model(knn_best_tune)|>\n",
    "  fit(knowledge_data_split_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8c241",
   "metadata": {},
   "source": [
    "#### 7. Predicting the model on the testing data set, and evaluating the model\n",
    "\n",
    "We first used the model to predict the knowledge levels of the testing set(table 9).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a16b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Predicting the UNS of testing data set\n",
    "knowledge_predictions= knn_fit|>\n",
    "  predict(knowledge_data_split_test)|>\n",
    "  bind_cols(knowledge_data_split_test)\n",
    "knowledge_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2fc9cd",
   "metadata": {},
   "source": [
    "##### Table 9: Predicted knowledge levels\n",
    "    This table represents the predicted knowledge level using the model, with the original testing set(Table 7). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea212143",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we calculated the corresponding accuracy and set up the confusion matrix, setting the truth to the actual Knowledge level(UNS),\n",
    "and comparing it to what the model predicted(.pred_class).\n",
    " $$𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 = \\frac{𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑐𝑜𝑟𝑟𝑒𝑐𝑡 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛} {𝑇𝑜𝑡𝑎𝑙 𝑛𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2372052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_metrics= knowledge_predictions|>\n",
    "  metrics(truth= UNS, estimate = .pred_class)|>\n",
    "  filter(.metric== \"accuracy\")\n",
    "knowledge_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03135c9e",
   "metadata": {},
   "source": [
    "##### Table 10: Accuracy of the model\n",
    "    This table represents the Accuracy of our model, ie 𝑁𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑐𝑜𝑟𝑟𝑒𝑐𝑡 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛 / 𝑇𝑜𝑡𝑎𝑙 𝑛𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠\n",
    "    Looking at the value of the .estimate variable, it shows that our model has an estimated accuracy on the testing set of ~92.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2adf04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knowledge_conf_mat= knowledge_predictions|>\n",
    "  conf_mat(truth= UNS, estimate = .pred_class)\n",
    "knowledge_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355a7d4",
   "metadata": {},
   "source": [
    "##### Table 11: Confusion matrix \n",
    "    This table represents the true number of each Knowledge level, and the predicted number of each Knowledge level.\n",
    "    The left column represents the predicted number of obseravtions, and the row represents the true number of obseravtions.\n",
    "    Looking at the table, The highest number of missed predictions of the Knowledge level came from the \"low\" class, \n",
    "    with a total of 8 missed predictions. All the other Knowledge level had only one missed predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a1158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repre.plot.width= 11, reper.plot.height = 9)\n",
    "\n",
    "#Number of Predicted cases \n",
    "count <- knowledge_predictions|>\n",
    "    group_by(.pred_class) |>\n",
    "    summarize(count = n())|>\n",
    "    rename(UNS = .pred_class)|>\n",
    "    mutate(UNS = fct_recode(UNS, pred_High = \"High\", pred_Low = \"Low\", pred_Middle = \"Middle\", pred_Very_low = \"Very Low\"))\n",
    "\n",
    "#Number of True cases \n",
    "count2 <- knowledge_predictions|>\n",
    "    group_by(UNS) |>\n",
    "    summarize(count = n())\n",
    "\n",
    "## Combining the Number of Predicted cases with Number of True cases \n",
    "count3 <- rbind(count, count2)|>\n",
    "    mutate(pred_or_true = UNS)|>\n",
    "     mutate(pred_or_true = fct_recode(UNS, Pred = \"pred_High\", Pred = \"pred_Low\", Pred = \"pred_Middle\", Pred = \"pred_Very_low\",\n",
    "                                     True = \"High\",\n",
    "                                     True = \"Low\",\n",
    "                                     True = \"Middle\",\n",
    "                                     True = \"Very Low\"))\n",
    "\n",
    "Compare_High <- count3|>\n",
    "    filter(UNS == \"pred_High\" | UNS== \"High\") |>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted High vs True High\")\n",
    "\n",
    "Compare_Middle <- count3|>\n",
    "    filter(UNS == \"pred_Middle\" | UNS== \"Middle\") |>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted Middle vs True Middle\")\n",
    "\n",
    "\n",
    "Compare_Low <- count3|>\n",
    "    filter(UNS== \"pred_Low\" | UNS== \"Low\")|>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted Low vs True Low\")\n",
    "\n",
    "Compare_Very_Low <- count3|>\n",
    "    filter(UNS== \"pred_Very_low\" | UNS== \"Very Low\")|>\n",
    "    ggplot(aes(x= UNS, y= count, fill=pred_or_true))+\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Knowledge level\") +\n",
    "    ylab(\"Number of Observations\")+\n",
    "    labs(fill = \"Prediction vs True\")+\n",
    "    ggtitle(\"Predicted Very Low vs True Very Low\")\n",
    "\n",
    "plot_grid(Compare_High, Compare_Middle,Compare_Low, Compare_Very_Low, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9cab6",
   "metadata": {},
   "source": [
    "##### Plot 2: Predicted vs True\n",
    "    This plot compares the amounts of true with the predicted number of each class levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a9dff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.4     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.1.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.1     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.3     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.4     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Use suppressPackageStartupMessages() to eliminate package startup messages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "<<<<<<< REMOTE CELL DELETED >>>>>>>\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "library(\"kknn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228cf38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `` -> `...7`\n",
      "\u001b[36m•\u001b[39m `` -> `...8`\n",
      "\u001b[36m•\u001b[39m `` -> `...9`\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m404\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m9\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (1): UNS\n",
      "\u001b[32mdbl\u001b[39m (5): STG, SCG, STR, LPR, PEG\n",
      "\u001b[33mlgl\u001b[39m (3): ...7, ...8, ...9\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 282 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>STG</th><th scope=col>SCG</th><th scope=col>STR</th><th scope=col>LPR</th><th scope=col>PEG</th><th scope=col>UNS</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00</td><td>0.00</td><td>0.50</td><td>0.20</td><td>0.85</td><td>High    </td></tr>\n",
       "\t<tr><td>0.18</td><td>0.18</td><td>0.55</td><td>0.30</td><td>0.81</td><td>High    </td></tr>\n",
       "\t<tr><td>0.05</td><td>0.07</td><td>0.70</td><td>0.01</td><td>0.05</td><td>very_low</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>0.68</td><td>0.43</td><td>0.60</td><td>0.47</td><td>0.55</td><td>Middle</td></tr>\n",
       "\t<tr><td>0.66</td><td>0.68</td><td>0.81</td><td>0.57</td><td>0.57</td><td>Middle</td></tr>\n",
       "\t<tr><td>  NA</td><td>  NA</td><td>  NA</td><td>  NA</td><td>  NA</td><td>NA    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 282 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " STG & SCG & STR & LPR & PEG & UNS\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 0.00 & 0.00 & 0.50 & 0.20 & 0.85 & High    \\\\\n",
       "\t 0.18 & 0.18 & 0.55 & 0.30 & 0.81 & High    \\\\\n",
       "\t 0.05 & 0.07 & 0.70 & 0.01 & 0.05 & very\\_low\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 0.68 & 0.43 & 0.60 & 0.47 & 0.55 & Middle\\\\\n",
       "\t 0.66 & 0.68 & 0.81 & 0.57 & 0.57 & Middle\\\\\n",
       "\t   NA &   NA &   NA &   NA &   NA & NA    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 282 × 6\n",
       "\n",
       "| STG &lt;dbl&gt; | SCG &lt;dbl&gt; | STR &lt;dbl&gt; | LPR &lt;dbl&gt; | PEG &lt;dbl&gt; | UNS &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 0.00 | 0.00 | 0.50 | 0.20 | 0.85 | High     |\n",
       "| 0.18 | 0.18 | 0.55 | 0.30 | 0.81 | High     |\n",
       "| 0.05 | 0.07 | 0.70 | 0.01 | 0.05 | very_low |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 0.68 | 0.43 | 0.60 | 0.47 | 0.55 | Middle |\n",
       "| 0.66 | 0.68 | 0.81 | 0.57 | 0.57 | Middle |\n",
       "|   NA |   NA |   NA |   NA |   NA | NA     |\n",
       "\n"
      ],
      "text/plain": [
       "    STG  SCG  STR  LPR  PEG  UNS     \n",
       "1   0.00 0.00 0.50 0.20 0.85 High    \n",
       "2   0.18 0.18 0.55 0.30 0.81 High    \n",
       "3   0.05 0.07 0.70 0.01 0.05 very_low\n",
       "⋮   ⋮    ⋮    ⋮    ⋮    ⋮    ⋮       \n",
       "280 0.68 0.43 0.60 0.47 0.55 Middle  \n",
       "281 0.66 0.68 0.81 0.57 0.57 Middle  \n",
       "282   NA   NA   NA   NA   NA NA      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mx\u001b[39m \u001b[31mFold1: internal:\n",
      "  \u001b[1m\u001b[33mError\u001b[31m in `purrr::map_chr()`:\u001b[22m\n",
      "  \u001b[1m\u001b[22m\u001b[36mℹ\u001b[31m In index: 1.\n",
      "  \u001b[1mCaused by error:\u001b[22m\n",
      "  \u001b[33m!\u001b[31m Result must be length 1, not 9.\u001b[39m\n",
      "\n",
      "\u001b[31mx\u001b[39m \u001b[31mFold2: preprocessor 1/1:\n",
      "  \u001b[1m\u001b[33mError\u001b[31m in `step_center()`:\u001b[22m\n",
      "  \u001b[1mCaused by error in `prep()`:\u001b[22m\n",
      "  \u001b[33m!\u001b[31m Can't subset columns with `data_recipe`.\n",
      "  \u001b[31m✖\u001b[31m `data_recipe` must be numeric or character, not a <recipe>...\u001b[39m\n",
      "\n",
      "\u001b[31mx\u001b[39m \u001b[31mFold3: preprocessor 1/1:\n",
      "  \u001b[1m\u001b[33mError\u001b[31m in `step_center()`:\u001b[22m\n",
      "  \u001b[1mCaused by error in `prep()`:\u001b[22m\n",
      "  \u001b[33m!\u001b[31m Can't subset columns with `data_recipe`.\n",
      "  \u001b[31m✖\u001b[31m `data_recipe` must be numeric or character, not a <recipe>...\u001b[39m\n",
      "\n",
      "\u001b[31mx\u001b[39m \u001b[31mFold4: preprocessor 1/1:\n",
      "  \u001b[1m\u001b[33mError\u001b[31m in `step_center()`:\u001b[22m\n",
      "  \u001b[1mCaused by error in `prep()`:\u001b[22m\n",
      "  \u001b[33m!\u001b[31m Can't subset columns with `data_recipe`.\n",
      "  \u001b[31m✖\u001b[31m `data_recipe` must be numeric or character, not a <recipe>...\u001b[39m\n",
      "\n",
      "\u001b[31mx\u001b[39m \u001b[31mFold5: preprocessor 1/1:\n",
      "  \u001b[1m\u001b[33mError\u001b[31m in `step_center()`:\u001b[22m\n",
      "  \u001b[1mCaused by error in `prep()`:\u001b[22m\n",
      "  \u001b[33m!\u001b[31m Can't subset columns with `data_recipe`.\n",
      "  \u001b[31m✖\u001b[31m `data_recipe` must be numeric or character, not a <recipe>...\u001b[39m\n",
      "\n",
      "Warning message:\n",
      "“All models failed. Run `show_notes(.Last.tune.result)` for more information.”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "\u001b[1m\u001b[33mError\u001b[39m in `estimate_tune_results()`:\u001b[22m\n\u001b[33m!\u001b[39m All of the models failed. See the .notes column.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[33mError\u001b[39m in `estimate_tune_results()`:\u001b[22m\n\u001b[33m!\u001b[39m All of the models failed. See the .notes column.\nTraceback:\n",
      "1. filter(collect_metrics(tune_grid(add_model(add_recipe(workflow(), \n .     data_recipe), knn_tune), resamples = training_vfold, grid = K)), \n .     .metric == \"accuracy\")",
      "2. collect_metrics(tune_grid(add_model(add_recipe(workflow(), data_recipe), \n .     knn_tune), resamples = training_vfold, grid = K))",
      "3. collect_metrics.tune_results(tune_grid(add_model(add_recipe(workflow(), \n .     data_recipe), knn_tune), resamples = training_vfold, grid = K))",
      "4. estimate_tune_results(x)",
      "5. rlang::abort(\"All of the models failed. See the .notes column.\")",
      "6. signal_abort(cnd, .file)"
     ]
    }
   ],
   "source": [
    "set.seed(1234) \n",
    "options(repr.plot.height = 5, repr.plot.width = 6)\n",
    "\n",
    "url <- \"https://github.com/JackyLinllk/ubc_dsci100_assignment/raw/main/data/Data_User_Modeling_Dataset_full.csv\"\n",
    "\n",
    "knowledge_data<-read_csv(url)|>\n",
    "    select(STG:UNS)|>\n",
    "    mutate(UNS = as.factor(UNS))\n",
    "\n",
    "knowledge_data_split <- initial_split(knowledge_data, prop = 0.70, strata = UNS)  \n",
    "   knowledge_data_split_train <- training(knowledge_data_split)\n",
    "   knowledge_data_split_test <- testing(knowledge_data_split)\n",
    "\n",
    "knowledge_data_split_train\n",
    "\n",
    "# your code here\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "data_recipe <- recipe(UNS ~. , data = knowledge_data_split_train)|>\n",
    "    step_center(data_recipe)|>\n",
    "    step_scale(data_recipe)\n",
    "\n",
    "training_vfold <-  vfold_cv(knowledge_data_split_train, v=5, strata = UNS)\n",
    "\n",
    "K <- tibble(neighbors = seq(1,6))\n",
    "\n",
    "knn_result <- workflow() |>\n",
    "    add_recipe(data_recipe) |>\n",
    "    add_model(knn_tune)|>\n",
    "    tune_grid(resamples = training_vfold, grid = K) |>\n",
    "    collect_metrics()|>\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "cross_val_plot <- ggplot(knn_result, aes(x=neighbors, y= mean)) +\n",
    "    geom_point() +\n",
    "       geom_line() +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") \n",
    "cross_val_plot\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c279f",
   "metadata": {},
   "source": [
    "Discussion:\n",
    " \n",
    "Using the optimal k-value (k=1) for the knn algorithm, our model has predicted the knowledge level for each student in the dataset. The accuracy rate is 93% (rounded up to the nearest percent). Overall, our model’s prediction tends to correspond with the labeled category of student performance. Therefore, we conclude that our model can accurately predict student performance in this data set.\n",
    " \n",
    "Our model’s predictions have not shown too much discrepancy in the accuracy across the four categories. However, it should be noted that our model has highest accuracy in predicting the category labeled as “High”, with only one missed prediction, and is less accurate in predicting the category labeled as “Low”, with 8 missed predictions in a total of 39 observations(table 11). Although 8 is not large enough to be considered as a remarkable number, the cause for this difference is worth potential future investigation.\n",
    " \n",
    "Overall, this result of this analysis is what we anticipated in our hypothesis. With a 93% accuracy rate, most of the predictions align with their labeled category in this dataset. However, our analysis based on the knn algorithm does not provide sufficient information to compare the significance of different variables on the labeled categories.\n",
    " \n",
    "This model provides valuable real-life applications as it could potentially be applied to the current education system. Compared to the traditional letter grade grading system, the system used in this dataset has more criteria that brings in a more diverse perspective to assessing student learning. Our algorithm could help bring this system into practical use by using the algorithm to assign the category instead of human assignment(educators, authorities etc.), which avoids subjective bias. This could also allow this grading system to be applied across different educational institutions as the category assignment is universal and objective, in which the influence that the discrepancy between each individual graders has on the result could be minimized. \n",
    " \n",
    "Looking at the potential real life application of this model, it leads the way to future questions such as: How can we adapt the model to predict the knowledge level for a data set that incorporates more variables? This question is worth investigation as the criterion for this grading system could be modified or extended to fit more educational needs of different institutions.\n",
    "\n",
    "Another future question could be targeted towards finding out which one out of the five variables has more influence on an individual’s knowledge level in this dataset. This question was originally proposed in our hypothesis, however, the findings of this analysis focused on the overall categorical prediction instead of comparing the significance across the five variables. In future investigation, we could focus on evaluating the relevance of each variable on the knowledge level by using the forward selection method that produces the optimal number of relevant variables (predictors). By comparing the accuracy of the five single-predictor combinations, we can tell which predictor has higher accuracy and is therefore more significant in predicting the knowledge level. If any variable is found to be rather irrelevant to predicting the knowledge level, it could be filtered out and thus improve the accuracy of the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd666185",
   "metadata": {},
   "source": [
    "References\n",
    "At least 2 citations of literature relevant to the project (format is your choice, just be consistent across the references).\n",
    "Make sure to cite the source of your data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cffae",
   "metadata": {},
   "source": [
    "References: \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

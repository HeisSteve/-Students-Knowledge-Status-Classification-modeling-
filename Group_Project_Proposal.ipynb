{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9a07b8-53a4-4e74-bdc5-6a55a217d38d",
   "metadata": {},
   "source": [
    "Title: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95205d5c-5ff3-4a28-8d74-ef0247d69110",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "Provide some relevant background information on the topic so that someone unfamiliar with it will be prepared to understand the rest of your proposal\n",
    "Clearly state the question you will try to answer with your project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f30f3-226d-4a3b-bc03-b358396f94e7",
   "metadata": {},
   "source": [
    "Preliminary exploratory data analysis:\n",
    "\n",
    "Demonstrate that the dataset can be read from the web into R \n",
    "Clean and wrangle your data into a tidy format\n",
    "Using only training data, summarize the data in at least one table (this is exploratory data analysis). An example of a useful table could be one that reports the number of observations in each class, the means of the predictor variables you plan to use in your analysis and how many rows have missing data. \n",
    "Using only training data, visualize the data with at least one plot relevant to the analysis you plan to do (this is exploratory data analysis). An example of a useful visualization could be one that compares the distributions of each of the predictor variables you plan to use in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e388c00-18be-46a1-9148-c03dc955ec4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table style=\"width: 100%;\"><tr><td>read_delim {readr}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Read a delimited file (including CSV and TSV) into a tibble</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>read_csv()</code> and <code>read_tsv()</code> are special cases of the more general\n",
       "<code>read_delim()</code>. They're useful for reading the most common types of\n",
       "flat file data, comma separated values and tab separated values,\n",
       "respectively. <code>read_csv2()</code> uses <code style=\"white-space: pre;\">&#8288;;&#8288;</code> for the field separator and <code style=\"white-space: pre;\">&#8288;,&#8288;</code> for the\n",
       "decimal point. This format is common in some European countries.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre><code class='language-R'>read_delim(\n",
       "  file,\n",
       "  delim = NULL,\n",
       "  quote = \"\\\"\",\n",
       "  escape_backslash = FALSE,\n",
       "  escape_double = TRUE,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  comment = \"\",\n",
       "  trim_ws = FALSE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv2(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_tsv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "</code></pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table>\n",
       "<tr style=\"vertical-align: top;\"><td><code>file</code></td>\n",
       "<td>\n",
       "<p>Either a path to a file, a connection, or literal data\n",
       "(either a single string or a raw vector).\n",
       "</p>\n",
       "<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will\n",
       "be automatically uncompressed. Files starting with <code style=\"white-space: pre;\">&#8288;http://&#8288;</code>,\n",
       "<code style=\"white-space: pre;\">&#8288;https://&#8288;</code>, <code style=\"white-space: pre;\">&#8288;ftp://&#8288;</code>, or <code style=\"white-space: pre;\">&#8288;ftps://&#8288;</code> will be automatically\n",
       "downloaded. Remote gz files can also be automatically downloaded and\n",
       "decompressed.\n",
       "</p>\n",
       "<p>Literal data is most useful for examples and tests. To be recognised as\n",
       "literal data, the input must be either wrapped with <code>I()</code>, be a string\n",
       "containing at least one new line, or be a vector containing at least one\n",
       "string with a new line.\n",
       "</p>\n",
       "<p>Using a value of <code>clipboard()</code> will read from the system clipboard.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>delim</code></td>\n",
       "<td>\n",
       "<p>Single character used to separate fields within a record.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>quote</code></td>\n",
       "<td>\n",
       "<p>Single character used to quote strings.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>escape_backslash</code></td>\n",
       "<td>\n",
       "<p>Does the file use backslashes to escape special\n",
       "characters? This is more general than <code>escape_double</code> as backslashes\n",
       "can be used to escape the delimiter character, the quote character, or\n",
       "to add special characters like <code style=\"white-space: pre;\">&#8288;\\\\n&#8288;</code>.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>escape_double</code></td>\n",
       "<td>\n",
       "<p>Does the file escape quotes by doubling them?\n",
       "i.e. If this option is <code>TRUE</code>, the value <code style=\"white-space: pre;\">&#8288;\"\"\"\"&#8288;</code> represents\n",
       "a single quote, <code style=\"white-space: pre;\">&#8288;\\\"&#8288;</code>.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>col_names</code></td>\n",
       "<td>\n",
       "<p>Either <code>TRUE</code>, <code>FALSE</code> or a character vector\n",
       "of column names.\n",
       "</p>\n",
       "<p>If <code>TRUE</code>, the first row of the input will be used as the column\n",
       "names, and will not be included in the data frame. If <code>FALSE</code>, column\n",
       "names will be generated automatically: X1, X2, X3 etc.\n",
       "</p>\n",
       "<p>If <code>col_names</code> is a character vector, the values will be used as the\n",
       "names of the columns, and the first row of the input will be read into\n",
       "the first row of the output data frame.\n",
       "</p>\n",
       "<p>Missing (<code>NA</code>) column names will generate a warning, and be filled\n",
       "in with dummy names <code>...1</code>, <code>...2</code> etc. Duplicate column names\n",
       "will generate a warning and be made unique, see <code>name_repair</code> to control\n",
       "how this is done.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>col_types</code></td>\n",
       "<td>\n",
       "<p>One of <code>NULL</code>, a <code>cols()</code> specification, or\n",
       "a string. See <code>vignette(\"readr\")</code> for more details.\n",
       "</p>\n",
       "<p>If <code>NULL</code>, all column types will be imputed from <code>guess_max</code> rows\n",
       "on the input interspersed throughout the file. This is convenient (and\n",
       "fast), but not robust. If the imputation fails, you'll need to increase\n",
       "the <code>guess_max</code> or supply the correct types yourself.\n",
       "</p>\n",
       "<p>Column specifications created by <code>list()</code> or <code>cols()</code> must contain\n",
       "one column specification for each column. If you only want to read a\n",
       "subset of the columns, use <code>cols_only()</code>.\n",
       "</p>\n",
       "<p>Alternatively, you can use a compact string representation where each\n",
       "character represents one column:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> c = character\n",
       "</p>\n",
       "</li>\n",
       "<li><p> i = integer\n",
       "</p>\n",
       "</li>\n",
       "<li><p> n = number\n",
       "</p>\n",
       "</li>\n",
       "<li><p> d = double\n",
       "</p>\n",
       "</li>\n",
       "<li><p> l = logical\n",
       "</p>\n",
       "</li>\n",
       "<li><p> f = factor\n",
       "</p>\n",
       "</li>\n",
       "<li><p> D = date\n",
       "</p>\n",
       "</li>\n",
       "<li><p> T = date time\n",
       "</p>\n",
       "</li>\n",
       "<li><p> t = time\n",
       "</p>\n",
       "</li>\n",
       "<li><p> ? = guess\n",
       "</p>\n",
       "</li>\n",
       "<li><p> _ or - = skip\n",
       "</p>\n",
       "<p>By default, reading a file without a column specification will print a\n",
       "message showing what <code>readr</code> guessed they were. To remove this message,\n",
       "set <code>show_col_types = FALSE</code> or set 'options(readr.show_col_types = FALSE).\n",
       "</p>\n",
       "</li></ul>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>col_select</code></td>\n",
       "<td>\n",
       "<p>Columns to include in the results. You can use the same\n",
       "mini-language as <code>dplyr::select()</code> to refer to the columns by name. Use\n",
       "<code>c()</code> to use more than one selection expression. Although this\n",
       "usage is less common, <code>col_select</code> also accepts a numeric column index. See\n",
       "<code>?tidyselect::language</code> for full details on the\n",
       "selection language.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>id</code></td>\n",
       "<td>\n",
       "<p>The name of a column in which to store the file path. This is\n",
       "useful when reading multiple input files and there is data in the file\n",
       "paths, such as the data collection date. If <code>NULL</code> (the default) no extra\n",
       "column is created.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>locale</code></td>\n",
       "<td>\n",
       "<p>The locale controls defaults that vary from place to place.\n",
       "The default locale is US-centric (like R), but you can use\n",
       "<code>locale()</code> to create your own locale that controls things like\n",
       "the default time zone, encoding, decimal mark, big mark, and day/month\n",
       "names.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>na</code></td>\n",
       "<td>\n",
       "<p>Character vector of strings to interpret as missing values. Set this\n",
       "option to <code>character()</code> to indicate no missing values.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>quoted_na</code></td>\n",
       "<td>\n",
       "<p><a href=\"https://lifecycle.r-lib.org/articles/stages.html#deprecated\"><img src=\"../help/figures/lifecycle-deprecated.svg\" alt='[Deprecated]' /></a> Should missing values\n",
       "inside quotes be treated as missing values (the default) or strings. This\n",
       "parameter is soft deprecated as of readr 2.0.0.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>comment</code></td>\n",
       "<td>\n",
       "<p>A string used to identify comments. Any text after the\n",
       "comment characters will be silently ignored.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>trim_ws</code></td>\n",
       "<td>\n",
       "<p>Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from\n",
       "each field before parsing it?</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>skip</code></td>\n",
       "<td>\n",
       "<p>Number of lines to skip before reading data. If <code>comment</code> is\n",
       "supplied any commented lines are ignored <em>after</em> skipping.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>n_max</code></td>\n",
       "<td>\n",
       "<p>Maximum number of lines to read.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>guess_max</code></td>\n",
       "<td>\n",
       "<p>Maximum number of lines to use for guessing column types.\n",
       "See <code>vignette(\"column-types\", package = \"readr\")</code> for more details.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>name_repair</code></td>\n",
       "<td>\n",
       "<p>Handling of column names. The default behaviour is to\n",
       "ensure column names are <code>\"unique\"</code>. Various repair strategies are\n",
       "supported:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>\"minimal\"</code>: No name repair or checks, beyond basic existence of names.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>\"unique\"</code> (default value): Make sure names are unique and not empty.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>\"check_unique\"</code>: no name repair, but check they are <code>unique</code>.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>\"universal\"</code>: Make the names <code>unique</code> and syntactic.\n",
       "</p>\n",
       "</li>\n",
       "<li><p> A function: apply custom name repair (e.g., <code>name_repair = make.names</code>\n",
       "for names in the style of base R).\n",
       "</p>\n",
       "</li>\n",
       "<li><p> A purrr-style anonymous function, see <code>rlang::as_function()</code>.\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>This argument is passed on as <code>repair</code> to <code>vctrs::vec_as_names()</code>.\n",
       "See there for more details on these terms and the strategies used\n",
       "to enforce them.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>num_threads</code></td>\n",
       "<td>\n",
       "<p>The number of processing threads to use for initial\n",
       "parsing and lazy reading of data. If your data contains newlines within\n",
       "fields the parser should automatically detect this and fall back to using\n",
       "one thread only. However if you know your file has newlines within quoted\n",
       "fields it is safest to set <code>num_threads = 1</code> explicitly.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>progress</code></td>\n",
       "<td>\n",
       "<p>Display a progress bar? By default it will only display\n",
       "in an interactive session and not while knitting a document. The automatic\n",
       "progress bar can be disabled by setting option <code>readr.show_progress</code> to\n",
       "<code>FALSE</code>.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>show_col_types</code></td>\n",
       "<td>\n",
       "<p>If <code>FALSE</code>, do not show the guessed column types. If\n",
       "<code>TRUE</code> always show the column types, even if they are supplied. If <code>NULL</code>\n",
       "(the default) only show the column types if they are not explicitly supplied\n",
       "by the <code>col_types</code> argument.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>skip_empty_rows</code></td>\n",
       "<td>\n",
       "<p>Should blank rows be ignored altogether? i.e. If this\n",
       "option is <code>TRUE</code> then blank rows will not be represented at all.  If it is\n",
       "<code>FALSE</code> then they will be represented by <code>NA</code> values in all the columns.</p>\n",
       "</td></tr>\n",
       "<tr style=\"vertical-align: top;\"><td><code>lazy</code></td>\n",
       "<td>\n",
       "<p>Read values lazily? By default, this is <code>FALSE</code>, because there\n",
       "are special considerations when reading a file lazily that have tripped up\n",
       "some users. Specifically, things get tricky when reading and then writing\n",
       "back into the same file. But, in general, lazy reading (<code>lazy = TRUE</code>) has\n",
       "many benefits, especially for interactive use and when your downstream work\n",
       "only involves a subset of the rows or columns.\n",
       "</p>\n",
       "<p>Learn more in <code>should_read_lazy()</code> and in the documentation for the\n",
       "<code>altrep</code> argument of <code>vroom::vroom()</code>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A <code>tibble()</code>. If there are parsing problems, a warning will alert you.\n",
       "You can retrieve the full details by calling <code>problems()</code> on your dataset.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre><code class='language-R'># Input sources -------------------------------------------------------------\n",
       "# Read from a path\n",
       "read_csv(readr_example(\"mtcars.csv\"))\n",
       "read_csv(readr_example(\"mtcars.csv.zip\"))\n",
       "read_csv(readr_example(\"mtcars.csv.bz2\"))\n",
       "## Not run: \n",
       "# Including remote paths\n",
       "read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n",
       "\n",
       "## End(Not run)\n",
       "\n",
       "# Read from multiple file paths at once\n",
       "continents &lt;- c(\"africa\", \"americas\", \"asia\", \"europe\", \"oceania\")\n",
       "filepaths &lt;- vapply(\n",
       "  paste0(\"mini-gapminder-\", continents, \".csv\"),\n",
       "  FUN = readr_example,\n",
       "  FUN.VALUE = character(1)\n",
       ")\n",
       "read_csv(filepaths, id = \"file\")\n",
       "\n",
       "# Or directly from a string with `I()`\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"))\n",
       "\n",
       "# Column selection-----------------------------------------------------------\n",
       "# Pass column names or indexes directly to select them\n",
       "read_csv(readr_example(\"chickens.csv\"), col_select = c(chicken, eggs_laid))\n",
       "read_csv(readr_example(\"chickens.csv\"), col_select = c(1, 3:4))\n",
       "\n",
       "# Or use the selection helpers\n",
       "read_csv(\n",
       "  readr_example(\"chickens.csv\"),\n",
       "  col_select = c(starts_with(\"c\"), last_col())\n",
       ")\n",
       "\n",
       "# You can also rename specific columns\n",
       "read_csv(\n",
       "  readr_example(\"chickens.csv\"),\n",
       "  col_select = c(egg_yield = eggs_laid, everything())\n",
       ")\n",
       "\n",
       "# Column types --------------------------------------------------------------\n",
       "# By default, readr guesses the columns types, looking at `guess_max` rows.\n",
       "# You can override with a compact specification:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n",
       "\n",
       "# Or with a list of column types:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n",
       "\n",
       "# If there are parsing problems, you get a warning, and can extract\n",
       "# more details with problems()\n",
       "y &lt;- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\n",
       "y\n",
       "problems(y)\n",
       "\n",
       "# Column names --------------------------------------------------------------\n",
       "# By default, readr duplicate name repair is noisy\n",
       "read_csv(I(\"x,x\\n1,2\\n3,4\"))\n",
       "\n",
       "# To quiet, set the option that controls verbosity of name repair\n",
       "withr::with_options(\n",
       "  list(rlib_name_repair_verbosity = \"quiet\"),\n",
       "  read_csv(I(\"x,x\\n1,2\\n3,4\"))\n",
       ")\n",
       "\n",
       "# Or use \"minimal\" to turn off name repair\n",
       "read_csv(I(\"x,x\\n1,2\\n3,4\"), name_repair = \"minimal\")\n",
       "\n",
       "# File types ----------------------------------------------------------------\n",
       "read_csv(I(\"a,b\\n1.0,2.0\"))\n",
       "read_csv2(I(\"a;b\\n1,0;2,0\"))\n",
       "read_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\n",
       "read_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n",
       "</code></pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>readr</em> version 2.1.3 ]</div>\n",
       "</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{read\\_delim}{Read a delimited file (including CSV and TSV) into a tibble}{read.Rul.delim}\n",
       "\\aliasA{read\\_csv}{read\\_delim}{read.Rul.csv}\n",
       "\\aliasA{read\\_csv2}{read\\_delim}{read.Rul.csv2}\n",
       "\\aliasA{read\\_tsv}{read\\_delim}{read.Rul.tsv}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{read\\_csv()} and \\code{read\\_tsv()} are special cases of the more general\n",
       "\\code{read\\_delim()}. They're useful for reading the most common types of\n",
       "flat file data, comma separated values and tab separated values,\n",
       "respectively. \\code{read\\_csv2()} uses \\AsIs{\\texttt{;}} for the field separator and \\AsIs{\\texttt{,}} for the\n",
       "decimal point. This format is common in some European countries.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "read_delim(\n",
       "  file,\n",
       "  delim = NULL,\n",
       "  quote = \"\\\"\",\n",
       "  escape_backslash = FALSE,\n",
       "  escape_double = TRUE,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  comment = \"\",\n",
       "  trim_ws = FALSE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  progress = show_progress(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_csv2(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\n",
       "read_tsv(\n",
       "  file,\n",
       "  col_names = TRUE,\n",
       "  col_types = NULL,\n",
       "  col_select = NULL,\n",
       "  id = NULL,\n",
       "  locale = default_locale(),\n",
       "  na = c(\"\", \"NA\"),\n",
       "  quoted_na = TRUE,\n",
       "  quote = \"\\\"\",\n",
       "  comment = \"\",\n",
       "  trim_ws = TRUE,\n",
       "  skip = 0,\n",
       "  n_max = Inf,\n",
       "  guess_max = min(1000, n_max),\n",
       "  progress = show_progress(),\n",
       "  name_repair = \"unique\",\n",
       "  num_threads = readr_threads(),\n",
       "  show_col_types = should_show_types(),\n",
       "  skip_empty_rows = TRUE,\n",
       "  lazy = should_read_lazy()\n",
       ")\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{file}] Either a path to a file, a connection, or literal data\n",
       "(either a single string or a raw vector).\n",
       "\n",
       "Files ending in \\code{.gz}, \\code{.bz2}, \\code{.xz}, or \\code{.zip} will\n",
       "be automatically uncompressed. Files starting with \\AsIs{\\texttt{http://}},\n",
       "\\AsIs{\\texttt{https://}}, \\AsIs{\\texttt{ftp://}}, or \\AsIs{\\texttt{ftps://}} will be automatically\n",
       "downloaded. Remote gz files can also be automatically downloaded and\n",
       "decompressed.\n",
       "\n",
       "Literal data is most useful for examples and tests. To be recognised as\n",
       "literal data, the input must be either wrapped with \\code{I()}, be a string\n",
       "containing at least one new line, or be a vector containing at least one\n",
       "string with a new line.\n",
       "\n",
       "Using a value of \\code{\\LinkA{clipboard()}{clipboard}} will read from the system clipboard.\n",
       "\n",
       "\\item[\\code{delim}] Single character used to separate fields within a record.\n",
       "\n",
       "\\item[\\code{quote}] Single character used to quote strings.\n",
       "\n",
       "\\item[\\code{escape\\_backslash}] Does the file use backslashes to escape special\n",
       "characters? This is more general than \\code{escape\\_double} as backslashes\n",
       "can be used to escape the delimiter character, the quote character, or\n",
       "to add special characters like \\AsIs{\\texttt{\\bsl{}\\bsl{}n}}.\n",
       "\n",
       "\\item[\\code{escape\\_double}] Does the file escape quotes by doubling them?\n",
       "i.e. If this option is \\code{TRUE}, the value \\AsIs{\\texttt{\"\"\"\"}} represents\n",
       "a single quote, \\AsIs{\\texttt{\\bsl{}\"}}.\n",
       "\n",
       "\\item[\\code{col\\_names}] Either \\code{TRUE}, \\code{FALSE} or a character vector\n",
       "of column names.\n",
       "\n",
       "If \\code{TRUE}, the first row of the input will be used as the column\n",
       "names, and will not be included in the data frame. If \\code{FALSE}, column\n",
       "names will be generated automatically: X1, X2, X3 etc.\n",
       "\n",
       "If \\code{col\\_names} is a character vector, the values will be used as the\n",
       "names of the columns, and the first row of the input will be read into\n",
       "the first row of the output data frame.\n",
       "\n",
       "Missing (\\code{NA}) column names will generate a warning, and be filled\n",
       "in with dummy names \\code{...1}, \\code{...2} etc. Duplicate column names\n",
       "will generate a warning and be made unique, see \\code{name\\_repair} to control\n",
       "how this is done.\n",
       "\n",
       "\\item[\\code{col\\_types}] One of \\code{NULL}, a \\code{\\LinkA{cols()}{cols}} specification, or\n",
       "a string. See \\code{vignette(\"readr\")} for more details.\n",
       "\n",
       "If \\code{NULL}, all column types will be imputed from \\code{guess\\_max} rows\n",
       "on the input interspersed throughout the file. This is convenient (and\n",
       "fast), but not robust. If the imputation fails, you'll need to increase\n",
       "the \\code{guess\\_max} or supply the correct types yourself.\n",
       "\n",
       "Column specifications created by \\code{\\LinkA{list()}{list}} or \\code{\\LinkA{cols()}{cols}} must contain\n",
       "one column specification for each column. If you only want to read a\n",
       "subset of the columns, use \\code{\\LinkA{cols\\_only()}{cols.Rul.only}}.\n",
       "\n",
       "Alternatively, you can use a compact string representation where each\n",
       "character represents one column:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} c = character\n",
       "\\item{} i = integer\n",
       "\\item{} n = number\n",
       "\\item{} d = double\n",
       "\\item{} l = logical\n",
       "\\item{} f = factor\n",
       "\\item{} D = date\n",
       "\\item{} T = date time\n",
       "\\item{} t = time\n",
       "\\item{} ? = guess\n",
       "\\item{} \\_ or - = skip\n",
       "\n",
       "By default, reading a file without a column specification will print a\n",
       "message showing what \\code{readr} guessed they were. To remove this message,\n",
       "set \\code{show\\_col\\_types = FALSE} or set `options(readr.show\\_col\\_types = FALSE).\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "\\item[\\code{col\\_select}] Columns to include in the results. You can use the same\n",
       "mini-language as \\code{dplyr::select()} to refer to the columns by name. Use\n",
       "\\code{c()} to use more than one selection expression. Although this\n",
       "usage is less common, \\code{col\\_select} also accepts a numeric column index. See\n",
       "\\code{\\LinkA{?tidyselect::language}{?tidyselect::language}} for full details on the\n",
       "selection language.\n",
       "\n",
       "\\item[\\code{id}] The name of a column in which to store the file path. This is\n",
       "useful when reading multiple input files and there is data in the file\n",
       "paths, such as the data collection date. If \\code{NULL} (the default) no extra\n",
       "column is created.\n",
       "\n",
       "\\item[\\code{locale}] The locale controls defaults that vary from place to place.\n",
       "The default locale is US-centric (like R), but you can use\n",
       "\\code{\\LinkA{locale()}{locale}} to create your own locale that controls things like\n",
       "the default time zone, encoding, decimal mark, big mark, and day/month\n",
       "names.\n",
       "\n",
       "\\item[\\code{na}] Character vector of strings to interpret as missing values. Set this\n",
       "option to \\code{character()} to indicate no missing values.\n",
       "\n",
       "\\item[\\code{quoted\\_na}] \\strong{[Deprecated]} Should missing values\n",
       "inside quotes be treated as missing values (the default) or strings. This\n",
       "parameter is soft deprecated as of readr 2.0.0.\n",
       "\n",
       "\\item[\\code{comment}] A string used to identify comments. Any text after the\n",
       "comment characters will be silently ignored.\n",
       "\n",
       "\\item[\\code{trim\\_ws}] Should leading and trailing whitespace (ASCII spaces and tabs) be trimmed from\n",
       "each field before parsing it?\n",
       "\n",
       "\\item[\\code{skip}] Number of lines to skip before reading data. If \\code{comment} is\n",
       "supplied any commented lines are ignored \\emph{after} skipping.\n",
       "\n",
       "\\item[\\code{n\\_max}] Maximum number of lines to read.\n",
       "\n",
       "\\item[\\code{guess\\_max}] Maximum number of lines to use for guessing column types.\n",
       "See \\code{vignette(\"column-types\", package = \"readr\")} for more details.\n",
       "\n",
       "\\item[\\code{name\\_repair}] Handling of column names. The default behaviour is to\n",
       "ensure column names are \\code{\"unique\"}. Various repair strategies are\n",
       "supported:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} \\code{\"minimal\"}: No name repair or checks, beyond basic existence of names.\n",
       "\\item{} \\code{\"unique\"} (default value): Make sure names are unique and not empty.\n",
       "\\item{} \\code{\"check\\_unique\"}: no name repair, but check they are \\code{unique}.\n",
       "\\item{} \\code{\"universal\"}: Make the names \\code{unique} and syntactic.\n",
       "\\item{} A function: apply custom name repair (e.g., \\code{name\\_repair = make.names}\n",
       "for names in the style of base R).\n",
       "\\item{} A purrr-style anonymous function, see \\code{\\LinkA{rlang::as\\_function()}{rlang::as.Rul.function()}}.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "This argument is passed on as \\code{repair} to \\code{\\LinkA{vctrs::vec\\_as\\_names()}{vctrs::vec.Rul.as.Rul.names()}}.\n",
       "See there for more details on these terms and the strategies used\n",
       "to enforce them.\n",
       "\n",
       "\\item[\\code{num\\_threads}] The number of processing threads to use for initial\n",
       "parsing and lazy reading of data. If your data contains newlines within\n",
       "fields the parser should automatically detect this and fall back to using\n",
       "one thread only. However if you know your file has newlines within quoted\n",
       "fields it is safest to set \\code{num\\_threads = 1} explicitly.\n",
       "\n",
       "\\item[\\code{progress}] Display a progress bar? By default it will only display\n",
       "in an interactive session and not while knitting a document. The automatic\n",
       "progress bar can be disabled by setting option \\code{readr.show\\_progress} to\n",
       "\\code{FALSE}.\n",
       "\n",
       "\\item[\\code{show\\_col\\_types}] If \\code{FALSE}, do not show the guessed column types. If\n",
       "\\code{TRUE} always show the column types, even if they are supplied. If \\code{NULL}\n",
       "(the default) only show the column types if they are not explicitly supplied\n",
       "by the \\code{col\\_types} argument.\n",
       "\n",
       "\\item[\\code{skip\\_empty\\_rows}] Should blank rows be ignored altogether? i.e. If this\n",
       "option is \\code{TRUE} then blank rows will not be represented at all.  If it is\n",
       "\\code{FALSE} then they will be represented by \\code{NA} values in all the columns.\n",
       "\n",
       "\\item[\\code{lazy}] Read values lazily? By default, this is \\code{FALSE}, because there\n",
       "are special considerations when reading a file lazily that have tripped up\n",
       "some users. Specifically, things get tricky when reading and then writing\n",
       "back into the same file. But, in general, lazy reading (\\code{lazy = TRUE}) has\n",
       "many benefits, especially for interactive use and when your downstream work\n",
       "only involves a subset of the rows or columns.\n",
       "\n",
       "Learn more in \\code{\\LinkA{should\\_read\\_lazy()}{should.Rul.read.Rul.lazy}} and in the documentation for the\n",
       "\\code{altrep} argument of \\code{\\LinkA{vroom::vroom()}{vroom::vroom()}}.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Value}\n",
       "A \\code{\\LinkA{tibble()}{tibble}}. If there are parsing problems, a warning will alert you.\n",
       "You can retrieve the full details by calling \\code{\\LinkA{problems()}{problems}} on your dataset.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "# Input sources -------------------------------------------------------------\n",
       "# Read from a path\n",
       "read_csv(readr_example(\"mtcars.csv\"))\n",
       "read_csv(readr_example(\"mtcars.csv.zip\"))\n",
       "read_csv(readr_example(\"mtcars.csv.bz2\"))\n",
       "## Not run: \n",
       "# Including remote paths\n",
       "read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n",
       "\n",
       "## End(Not run)\n",
       "\n",
       "# Read from multiple file paths at once\n",
       "continents <- c(\"africa\", \"americas\", \"asia\", \"europe\", \"oceania\")\n",
       "filepaths <- vapply(\n",
       "  paste0(\"mini-gapminder-\", continents, \".csv\"),\n",
       "  FUN = readr_example,\n",
       "  FUN.VALUE = character(1)\n",
       ")\n",
       "read_csv(filepaths, id = \"file\")\n",
       "\n",
       "# Or directly from a string with `I()`\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"))\n",
       "\n",
       "# Column selection-----------------------------------------------------------\n",
       "# Pass column names or indexes directly to select them\n",
       "read_csv(readr_example(\"chickens.csv\"), col_select = c(chicken, eggs_laid))\n",
       "read_csv(readr_example(\"chickens.csv\"), col_select = c(1, 3:4))\n",
       "\n",
       "# Or use the selection helpers\n",
       "read_csv(\n",
       "  readr_example(\"chickens.csv\"),\n",
       "  col_select = c(starts_with(\"c\"), last_col())\n",
       ")\n",
       "\n",
       "# You can also rename specific columns\n",
       "read_csv(\n",
       "  readr_example(\"chickens.csv\"),\n",
       "  col_select = c(egg_yield = eggs_laid, everything())\n",
       ")\n",
       "\n",
       "# Column types --------------------------------------------------------------\n",
       "# By default, readr guesses the columns types, looking at `guess_max` rows.\n",
       "# You can override with a compact specification:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n",
       "\n",
       "# Or with a list of column types:\n",
       "read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n",
       "\n",
       "# If there are parsing problems, you get a warning, and can extract\n",
       "# more details with problems()\n",
       "y <- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\n",
       "y\n",
       "problems(y)\n",
       "\n",
       "# Column names --------------------------------------------------------------\n",
       "# By default, readr duplicate name repair is noisy\n",
       "read_csv(I(\"x,x\\n1,2\\n3,4\"))\n",
       "\n",
       "# To quiet, set the option that controls verbosity of name repair\n",
       "withr::with_options(\n",
       "  list(rlib_name_repair_verbosity = \"quiet\"),\n",
       "  read_csv(I(\"x,x\\n1,2\\n3,4\"))\n",
       ")\n",
       "\n",
       "# Or use \"minimal\" to turn off name repair\n",
       "read_csv(I(\"x,x\\n1,2\\n3,4\"), name_repair = \"minimal\")\n",
       "\n",
       "# File types ----------------------------------------------------------------\n",
       "read_csv(I(\"a,b\\n1.0,2.0\"))\n",
       "read_csv2(I(\"a;b\\n1,0;2,0\"))\n",
       "read_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\n",
       "read_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "read_delim                package:readr                R Documentation\n",
       "\n",
       "_\bR_\be_\ba_\bd _\ba _\bd_\be_\bl_\bi_\bm_\bi_\bt_\be_\bd _\bf_\bi_\bl_\be (_\bi_\bn_\bc_\bl_\bu_\bd_\bi_\bn_\bg _\bC_\bS_\bV _\ba_\bn_\bd _\bT_\bS_\bV) _\bi_\bn_\bt_\bo _\ba _\bt_\bi_\bb_\bb_\bl_\be\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘read_csv()’ and ‘read_tsv()’ are special cases of the more\n",
       "     general ‘read_delim()’. They're useful for reading the most common\n",
       "     types of flat file data, comma separated values and tab separated\n",
       "     values, respectively. ‘read_csv2()’ uses ; for the field separator\n",
       "     and , for the decimal point. This format is common in some\n",
       "     European countries.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     read_delim(\n",
       "       file,\n",
       "       delim = NULL,\n",
       "       quote = \"\\\"\",\n",
       "       escape_backslash = FALSE,\n",
       "       escape_double = TRUE,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       comment = \"\",\n",
       "       trim_ws = FALSE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       progress = show_progress(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "     read_csv(\n",
       "       file,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       quote = \"\\\"\",\n",
       "       comment = \"\",\n",
       "       trim_ws = TRUE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       progress = show_progress(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "     read_csv2(\n",
       "       file,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       quote = \"\\\"\",\n",
       "       comment = \"\",\n",
       "       trim_ws = TRUE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       progress = show_progress(),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "     read_tsv(\n",
       "       file,\n",
       "       col_names = TRUE,\n",
       "       col_types = NULL,\n",
       "       col_select = NULL,\n",
       "       id = NULL,\n",
       "       locale = default_locale(),\n",
       "       na = c(\"\", \"NA\"),\n",
       "       quoted_na = TRUE,\n",
       "       quote = \"\\\"\",\n",
       "       comment = \"\",\n",
       "       trim_ws = TRUE,\n",
       "       skip = 0,\n",
       "       n_max = Inf,\n",
       "       guess_max = min(1000, n_max),\n",
       "       progress = show_progress(),\n",
       "       name_repair = \"unique\",\n",
       "       num_threads = readr_threads(),\n",
       "       show_col_types = should_show_types(),\n",
       "       skip_empty_rows = TRUE,\n",
       "       lazy = should_read_lazy()\n",
       "     )\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "    file: Either a path to a file, a connection, or literal data\n",
       "          (either a single string or a raw vector).\n",
       "\n",
       "          Files ending in ‘.gz’, ‘.bz2’, ‘.xz’, or ‘.zip’ will be\n",
       "          automatically uncompressed. Files starting with http://,\n",
       "          https://, ftp://, or ftps:// will be automatically\n",
       "          downloaded. Remote gz files can also be automatically\n",
       "          downloaded and decompressed.\n",
       "\n",
       "          Literal data is most useful for examples and tests. To be\n",
       "          recognised as literal data, the input must be either wrapped\n",
       "          with ‘I()’, be a string containing at least one new line, or\n",
       "          be a vector containing at least one string with a new line.\n",
       "\n",
       "          Using a value of ‘clipboard()’ will read from the system\n",
       "          clipboard.\n",
       "\n",
       "   delim: Single character used to separate fields within a record.\n",
       "\n",
       "   quote: Single character used to quote strings.\n",
       "\n",
       "escape_backslash: Does the file use backslashes to escape special\n",
       "          characters? This is more general than ‘escape_double’ as\n",
       "          backslashes can be used to escape the delimiter character,\n",
       "          the quote character, or to add special characters like \\\\n.\n",
       "\n",
       "escape_double: Does the file escape quotes by doubling them? i.e. If\n",
       "          this option is ‘TRUE’, the value \"\"\"\" represents a single\n",
       "          quote, \\\".\n",
       "\n",
       "col_names: Either ‘TRUE’, ‘FALSE’ or a character vector of column\n",
       "          names.\n",
       "\n",
       "          If ‘TRUE’, the first row of the input will be used as the\n",
       "          column names, and will not be included in the data frame. If\n",
       "          ‘FALSE’, column names will be generated automatically: X1,\n",
       "          X2, X3 etc.\n",
       "\n",
       "          If ‘col_names’ is a character vector, the values will be used\n",
       "          as the names of the columns, and the first row of the input\n",
       "          will be read into the first row of the output data frame.\n",
       "\n",
       "          Missing (‘NA’) column names will generate a warning, and be\n",
       "          filled in with dummy names ‘...1’, ‘...2’ etc. Duplicate\n",
       "          column names will generate a warning and be made unique, see\n",
       "          ‘name_repair’ to control how this is done.\n",
       "\n",
       "col_types: One of ‘NULL’, a ‘cols()’ specification, or a string. See\n",
       "          ‘vignette(\"readr\")’ for more details.\n",
       "\n",
       "          If ‘NULL’, all column types will be imputed from ‘guess_max’\n",
       "          rows on the input interspersed throughout the file. This is\n",
       "          convenient (and fast), but not robust. If the imputation\n",
       "          fails, you'll need to increase the ‘guess_max’ or supply the\n",
       "          correct types yourself.\n",
       "\n",
       "          Column specifications created by ‘list()’ or ‘cols()’ must\n",
       "          contain one column specification for each column. If you only\n",
       "          want to read a subset of the columns, use ‘cols_only()’.\n",
       "\n",
       "          Alternatively, you can use a compact string representation\n",
       "          where each character represents one column:\n",
       "\n",
       "            • c = character\n",
       "\n",
       "            • i = integer\n",
       "\n",
       "            • n = number\n",
       "\n",
       "            • d = double\n",
       "\n",
       "            • l = logical\n",
       "\n",
       "            • f = factor\n",
       "\n",
       "            • D = date\n",
       "\n",
       "            • T = date time\n",
       "\n",
       "            • t = time\n",
       "\n",
       "            • ? = guess\n",
       "\n",
       "            • _ or - = skip\n",
       "\n",
       "              By default, reading a file without a column specification\n",
       "              will print a message showing what ‘readr’ guessed they\n",
       "              were. To remove this message, set ‘show_col_types =\n",
       "              FALSE’ or set `options(readr.show_col_types = FALSE).\n",
       "\n",
       "col_select: Columns to include in the results. You can use the same\n",
       "          mini-language as ‘dplyr::select()’ to refer to the columns by\n",
       "          name. Use ‘c()’ to use more than one selection expression.\n",
       "          Although this usage is less common, ‘col_select’ also accepts\n",
       "          a numeric column index. See ‘?tidyselect::language’ for full\n",
       "          details on the selection language.\n",
       "\n",
       "      id: The name of a column in which to store the file path. This is\n",
       "          useful when reading multiple input files and there is data in\n",
       "          the file paths, such as the data collection date. If ‘NULL’\n",
       "          (the default) no extra column is created.\n",
       "\n",
       "  locale: The locale controls defaults that vary from place to place.\n",
       "          The default locale is US-centric (like R), but you can use\n",
       "          ‘locale()’ to create your own locale that controls things\n",
       "          like the default time zone, encoding, decimal mark, big mark,\n",
       "          and day/month names.\n",
       "\n",
       "      na: Character vector of strings to interpret as missing values.\n",
       "          Set this option to ‘character()’ to indicate no missing\n",
       "          values.\n",
       "\n",
       "quoted_na: *[Deprecated]* Should missing values inside quotes be\n",
       "          treated as missing values (the default) or strings. This\n",
       "          parameter is soft deprecated as of readr 2.0.0.\n",
       "\n",
       " comment: A string used to identify comments. Any text after the\n",
       "          comment characters will be silently ignored.\n",
       "\n",
       " trim_ws: Should leading and trailing whitespace (ASCII spaces and\n",
       "          tabs) be trimmed from each field before parsing it?\n",
       "\n",
       "    skip: Number of lines to skip before reading data. If ‘comment’ is\n",
       "          supplied any commented lines are ignored _after_ skipping.\n",
       "\n",
       "   n_max: Maximum number of lines to read.\n",
       "\n",
       "guess_max: Maximum number of lines to use for guessing column types.\n",
       "          See ‘vignette(\"column-types\", package = \"readr\")’ for more\n",
       "          details.\n",
       "\n",
       "name_repair: Handling of column names. The default behaviour is to\n",
       "          ensure column names are ‘\"unique\"’. Various repair strategies\n",
       "          are supported:\n",
       "\n",
       "            • ‘\"minimal\"’: No name repair or checks, beyond basic\n",
       "              existence of names.\n",
       "\n",
       "            • ‘\"unique\"’ (default value): Make sure names are unique\n",
       "              and not empty.\n",
       "\n",
       "            • ‘\"check_unique\"’: no name repair, but check they are\n",
       "              ‘unique’.\n",
       "\n",
       "            • ‘\"universal\"’: Make the names ‘unique’ and syntactic.\n",
       "\n",
       "            • A function: apply custom name repair (e.g., ‘name_repair\n",
       "              = make.names’ for names in the style of base R).\n",
       "\n",
       "            • A purrr-style anonymous function, see\n",
       "              ‘rlang::as_function()’.\n",
       "\n",
       "          This argument is passed on as ‘repair’ to\n",
       "          ‘vctrs::vec_as_names()’. See there for more details on these\n",
       "          terms and the strategies used to enforce them.\n",
       "\n",
       "num_threads: The number of processing threads to use for initial\n",
       "          parsing and lazy reading of data. If your data contains\n",
       "          newlines within fields the parser should automatically detect\n",
       "          this and fall back to using one thread only. However if you\n",
       "          know your file has newlines within quoted fields it is safest\n",
       "          to set ‘num_threads = 1’ explicitly.\n",
       "\n",
       "progress: Display a progress bar? By default it will only display in an\n",
       "          interactive session and not while knitting a document. The\n",
       "          automatic progress bar can be disabled by setting option\n",
       "          ‘readr.show_progress’ to ‘FALSE’.\n",
       "\n",
       "show_col_types: If ‘FALSE’, do not show the guessed column types. If\n",
       "          ‘TRUE’ always show the column types, even if they are\n",
       "          supplied. If ‘NULL’ (the default) only show the column types\n",
       "          if they are not explicitly supplied by the ‘col_types’\n",
       "          argument.\n",
       "\n",
       "skip_empty_rows: Should blank rows be ignored altogether? i.e. If this\n",
       "          option is ‘TRUE’ then blank rows will not be represented at\n",
       "          all.  If it is ‘FALSE’ then they will be represented by ‘NA’\n",
       "          values in all the columns.\n",
       "\n",
       "    lazy: Read values lazily? By default, this is ‘FALSE’, because\n",
       "          there are special considerations when reading a file lazily\n",
       "          that have tripped up some users. Specifically, things get\n",
       "          tricky when reading and then writing back into the same file.\n",
       "          But, in general, lazy reading (‘lazy = TRUE’) has many\n",
       "          benefits, especially for interactive use and when your\n",
       "          downstream work only involves a subset of the rows or\n",
       "          columns.\n",
       "\n",
       "          Learn more in ‘should_read_lazy()’ and in the documentation\n",
       "          for the ‘altrep’ argument of ‘vroom::vroom()’.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A ‘tibble()’. If there are parsing problems, a warning will alert\n",
       "     you. You can retrieve the full details by calling ‘problems()’ on\n",
       "     your dataset.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # Input sources -------------------------------------------------------------\n",
       "     # Read from a path\n",
       "     read_csv(readr_example(\"mtcars.csv\"))\n",
       "     read_csv(readr_example(\"mtcars.csv.zip\"))\n",
       "     read_csv(readr_example(\"mtcars.csv.bz2\"))\n",
       "     ## Not run:\n",
       "     \n",
       "     # Including remote paths\n",
       "     read_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n",
       "     ## End(Not run)\n",
       "     \n",
       "     \n",
       "     # Read from multiple file paths at once\n",
       "     continents <- c(\"africa\", \"americas\", \"asia\", \"europe\", \"oceania\")\n",
       "     filepaths <- vapply(\n",
       "       paste0(\"mini-gapminder-\", continents, \".csv\"),\n",
       "       FUN = readr_example,\n",
       "       FUN.VALUE = character(1)\n",
       "     )\n",
       "     read_csv(filepaths, id = \"file\")\n",
       "     \n",
       "     # Or directly from a string with `I()`\n",
       "     read_csv(I(\"x,y\\n1,2\\n3,4\"))\n",
       "     \n",
       "     # Column selection-----------------------------------------------------------\n",
       "     # Pass column names or indexes directly to select them\n",
       "     read_csv(readr_example(\"chickens.csv\"), col_select = c(chicken, eggs_laid))\n",
       "     read_csv(readr_example(\"chickens.csv\"), col_select = c(1, 3:4))\n",
       "     \n",
       "     # Or use the selection helpers\n",
       "     read_csv(\n",
       "       readr_example(\"chickens.csv\"),\n",
       "       col_select = c(starts_with(\"c\"), last_col())\n",
       "     )\n",
       "     \n",
       "     # You can also rename specific columns\n",
       "     read_csv(\n",
       "       readr_example(\"chickens.csv\"),\n",
       "       col_select = c(egg_yield = eggs_laid, everything())\n",
       "     )\n",
       "     \n",
       "     # Column types --------------------------------------------------------------\n",
       "     # By default, readr guesses the columns types, looking at `guess_max` rows.\n",
       "     # You can override with a compact specification:\n",
       "     read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n",
       "     \n",
       "     # Or with a list of column types:\n",
       "     read_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n",
       "     \n",
       "     # If there are parsing problems, you get a warning, and can extract\n",
       "     # more details with problems()\n",
       "     y <- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\n",
       "     y\n",
       "     problems(y)\n",
       "     \n",
       "     # Column names --------------------------------------------------------------\n",
       "     # By default, readr duplicate name repair is noisy\n",
       "     read_csv(I(\"x,x\\n1,2\\n3,4\"))\n",
       "     \n",
       "     # To quiet, set the option that controls verbosity of name repair\n",
       "     withr::with_options(\n",
       "       list(rlib_name_repair_verbosity = \"quiet\"),\n",
       "       read_csv(I(\"x,x\\n1,2\\n3,4\"))\n",
       "     )\n",
       "     \n",
       "     # Or use \"minimal\" to turn off name repair\n",
       "     read_csv(I(\"x,x\\n1,2\\n3,4\"), name_repair = \"minimal\")\n",
       "     \n",
       "     # File types ----------------------------------------------------------------\n",
       "     read_csv(I(\"a,b\\n1.0,2.0\"))\n",
       "     read_csv2(I(\"a;b\\n1,0;2,0\"))\n",
       "     read_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\n",
       "     read_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "\n",
    "?read_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2f8dd3-895b-49c3-9e1b-1f36169b36c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m2293\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m10\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (10): ph, Hardness, Solids, Chloramines, Sulfate, Conductivity, Organic_...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2293 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ph</th><th scope=col>Hardness</th><th scope=col>Solids</th><th scope=col>Chloramines</th><th scope=col>Sulfate</th><th scope=col>Conductivity</th><th scope=col>Organic_carbon</th><th scope=col>Trihalomethanes</th><th scope=col>Turbidity</th><th scope=col>Potability</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>7.080795</td><td>219.6743</td><td>22210.61</td><td>5.875041</td><td>333.7758</td><td>398.5177</td><td>11.50232</td><td>112.41221</td><td>2.994259</td><td>Potable    </td></tr>\n",
       "\t<tr><td>6.783888</td><td>193.6536</td><td>13677.11</td><td>5.171454</td><td>323.7287</td><td>477.8547</td><td>15.05606</td><td> 66.39629</td><td>3.250022</td><td>Potable    </td></tr>\n",
       "\t<tr><td>6.010618</td><td>184.5586</td><td>15940.57</td><td>8.165222</td><td>421.4861</td><td>314.5298</td><td>20.31462</td><td> 83.70794</td><td>4.867287</td><td>Not Potable</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>7.790875</td><td>196.4787</td><td>24061.35</td><td>6.785685</td><td>350.1173</td><td>471.5185</td><td>15.34332</td><td>44.54463</td><td>3.076214</td><td>Potable    </td></tr>\n",
       "\t<tr><td>6.139743</td><td>168.4442</td><td>23894.14</td><td>9.494582</td><td>318.0261</td><td>494.1291</td><td>19.11602</td><td>60.26477</td><td>3.841222</td><td>Potable    </td></tr>\n",
       "\t<tr><td>7.080795</td><td>143.3002</td><td>16263.17</td><td>6.229737</td><td>333.7758</td><td>503.6641</td><td>19.58550</td><td>66.39629</td><td>3.451740</td><td>Not Potable</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2293 × 10\n",
       "\\begin{tabular}{llllllllll}\n",
       " ph & Hardness & Solids & Chloramines & Sulfate & Conductivity & Organic\\_carbon & Trihalomethanes & Turbidity & Potability\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 7.080795 & 219.6743 & 22210.61 & 5.875041 & 333.7758 & 398.5177 & 11.50232 & 112.41221 & 2.994259 & Potable    \\\\\n",
       "\t 6.783888 & 193.6536 & 13677.11 & 5.171454 & 323.7287 & 477.8547 & 15.05606 &  66.39629 & 3.250022 & Potable    \\\\\n",
       "\t 6.010618 & 184.5586 & 15940.57 & 8.165222 & 421.4861 & 314.5298 & 20.31462 &  83.70794 & 4.867287 & Not Potable\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 7.790875 & 196.4787 & 24061.35 & 6.785685 & 350.1173 & 471.5185 & 15.34332 & 44.54463 & 3.076214 & Potable    \\\\\n",
       "\t 6.139743 & 168.4442 & 23894.14 & 9.494582 & 318.0261 & 494.1291 & 19.11602 & 60.26477 & 3.841222 & Potable    \\\\\n",
       "\t 7.080795 & 143.3002 & 16263.17 & 6.229737 & 333.7758 & 503.6641 & 19.58550 & 66.39629 & 3.451740 & Not Potable\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2293 × 10\n",
       "\n",
       "| ph &lt;dbl&gt; | Hardness &lt;dbl&gt; | Solids &lt;dbl&gt; | Chloramines &lt;dbl&gt; | Sulfate &lt;dbl&gt; | Conductivity &lt;dbl&gt; | Organic_carbon &lt;dbl&gt; | Trihalomethanes &lt;dbl&gt; | Turbidity &lt;dbl&gt; | Potability &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 7.080795 | 219.6743 | 22210.61 | 5.875041 | 333.7758 | 398.5177 | 11.50232 | 112.41221 | 2.994259 | Potable     |\n",
       "| 6.783888 | 193.6536 | 13677.11 | 5.171454 | 323.7287 | 477.8547 | 15.05606 |  66.39629 | 3.250022 | Potable     |\n",
       "| 6.010618 | 184.5586 | 15940.57 | 8.165222 | 421.4861 | 314.5298 | 20.31462 |  83.70794 | 4.867287 | Not Potable |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 7.790875 | 196.4787 | 24061.35 | 6.785685 | 350.1173 | 471.5185 | 15.34332 | 44.54463 | 3.076214 | Potable     |\n",
       "| 6.139743 | 168.4442 | 23894.14 | 9.494582 | 318.0261 | 494.1291 | 19.11602 | 60.26477 | 3.841222 | Potable     |\n",
       "| 7.080795 | 143.3002 | 16263.17 | 6.229737 | 333.7758 | 503.6641 | 19.58550 | 66.39629 | 3.451740 | Not Potable |\n",
       "\n"
      ],
      "text/plain": [
       "     ph       Hardness Solids   Chloramines Sulfate  Conductivity\n",
       "1    7.080795 219.6743 22210.61 5.875041    333.7758 398.5177    \n",
       "2    6.783888 193.6536 13677.11 5.171454    323.7287 477.8547    \n",
       "3    6.010618 184.5586 15940.57 8.165222    421.4861 314.5298    \n",
       "⋮    ⋮        ⋮        ⋮        ⋮           ⋮        ⋮           \n",
       "2291 7.790875 196.4787 24061.35 6.785685    350.1173 471.5185    \n",
       "2292 6.139743 168.4442 23894.14 9.494582    318.0261 494.1291    \n",
       "2293 7.080795 143.3002 16263.17 6.229737    333.7758 503.6641    \n",
       "     Organic_carbon Trihalomethanes Turbidity Potability \n",
       "1    11.50232       112.41221       2.994259  Potable    \n",
       "2    15.05606        66.39629       3.250022  Potable    \n",
       "3    20.31462        83.70794       4.867287  Not Potable\n",
       "⋮    ⋮              ⋮               ⋮         ⋮          \n",
       "2291 15.34332       44.54463        3.076214  Potable    \n",
       "2292 19.11602       60.26477        3.841222  Potable    \n",
       "2293 19.58550       66.39629        3.451740  Not Potable"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Potability</th><th scope=col>count</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Potable    </td><td>1398</td></tr>\n",
       "\t<tr><td>Not Potable</td><td> 895</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Potability & count\\\\\n",
       " <fct> & <int>\\\\\n",
       "\\hline\n",
       "\t Potable     & 1398\\\\\n",
       "\t Not Potable &  895\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 2\n",
       "\n",
       "| Potability &lt;fct&gt; | count &lt;int&gt; |\n",
       "|---|---|\n",
       "| Potable     | 1398 |\n",
       "| Not Potable |  895 |\n",
       "\n"
      ],
      "text/plain": [
       "  Potability  count\n",
       "1 Potable     1398 \n",
       "2 Not Potable  895 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Potable_Observations</th><th scope=col>Not_Potable_Observations</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1398</td><td>895</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Potable\\_Observations & Not\\_Potable\\_Observations\\\\\n",
       " <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 1398 & 895\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 2\n",
       "\n",
       "| Potable_Observations &lt;int&gt; | Not_Potable_Observations &lt;int&gt; |\n",
       "|---|---|\n",
       "| 1398 | 895 |\n",
       "\n"
      ],
      "text/plain": [
       "  Potable_Observations Not_Potable_Observations\n",
       "1 1398                 895                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ph</th><th scope=col>Hardness</th><th scope=col>Solids</th><th scope=col>Chloramines</th><th scope=col>Sulfate</th><th scope=col>Conductivity</th><th scope=col>Organic_carbon</th><th scope=col>Trihalomethanes</th><th scope=col>Turbidity</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>7.082265</td><td>196.3903</td><td>22074.34</td><td>7.132987</td><td>333.3933</td><td>425.4557</td><td>14.22917</td><td>66.49952</td><td>3.967153</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " ph & Hardness & Solids & Chloramines & Sulfate & Conductivity & Organic\\_carbon & Trihalomethanes & Turbidity\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 7.082265 & 196.3903 & 22074.34 & 7.132987 & 333.3933 & 425.4557 & 14.22917 & 66.49952 & 3.967153\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 9\n",
       "\n",
       "| ph &lt;dbl&gt; | Hardness &lt;dbl&gt; | Solids &lt;dbl&gt; | Chloramines &lt;dbl&gt; | Sulfate &lt;dbl&gt; | Conductivity &lt;dbl&gt; | Organic_carbon &lt;dbl&gt; | Trihalomethanes &lt;dbl&gt; | Turbidity &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 7.082265 | 196.3903 | 22074.34 | 7.132987 | 333.3933 | 425.4557 | 14.22917 | 66.49952 | 3.967153 |\n",
       "\n"
      ],
      "text/plain": [
       "  ph       Hardness Solids   Chloramines Sulfate  Conductivity Organic_carbon\n",
       "1 7.082265 196.3903 22074.34 7.132987    333.3933 425.4557     14.22917      \n",
       "  Trihalomethanes Turbidity\n",
       "1 66.49952        3.967153 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <-\"https://github.com/JackyLinllk/ubc_dsci100_assignment/raw/main/data/train_dataset.csv\"\n",
    "water_data <-read_csv(url) |>\n",
    "    mutate(Potability = as.factor(Potability))|>\n",
    "    mutate(Potability = fct_recode(Potability, \"Potable\" = \"0\", \"Not Potable\" = \"1\"))\n",
    "water_data\n",
    "\n",
    "water_data_class_count <- water_data |>\n",
    "    group_by(Potability)|>\n",
    "    summarize(count = n())\n",
    "water_data_class_count \n",
    "\n",
    "water_data_class_count_wider <- pivot_wider(water_data_class_count, \n",
    "                                            names_from = Potability, values_from = count) |>\n",
    "            rename(\"Potable_Observations\" = \"Potable\", \"Not_Potable_Observations\" = \"Not Potable\" )\n",
    "\n",
    "water_data_class_count_wider\n",
    "\n",
    "water_data_predictor_mean <-water_data|>\n",
    "    select(-Potability)|>\n",
    "map_df(mean)\n",
    "\n",
    "water_data_predictor_mean\n",
    "\n",
    "#summarytable <- bind_cols(water_data_class_count_wider, water_data_map)\n",
    "#summarytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b43ef399-ebfb-4ed4-8978-6aedd998067b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loan_split <- initial_split(loan_data, prop = 0.75, strata = Default)  \n",
    "#loan_train <- training(loan_split)\n",
    "#loan_test <- testing(loan_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e56de-d499-4b31-9841-bc7189a7fe30",
   "metadata": {},
   "source": [
    "Methods:\n",
    "Explain how you will conduct either your data analysis and which variables/columns you will use. Note - you do not need to use all variables/columns that exist in the raw data set. In fact, that's often not a good idea. For each variable think: is this a useful variable for prediction?\n",
    "Describe at least one way that you will visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c09b94-4d2f-4a5f-8dc6-d6cf86308153",
   "metadata": {},
   "source": [
    "Expected outcomes and significance:\n",
    "What do you expect to find?\n",
    "What impact could such findings have?\n",
    "What future questions could this lead to?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
